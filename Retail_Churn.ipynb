{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ca7e3e-69ea-4c40-b8b1-a64c01e60915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c908491-03cf-4e97-ae11-de5d1c333e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Retail_Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81975fb0-9265-4697-ba1d-ca297723c700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Years_as_Customer</th>\n",
       "      <th>Num_of_Purchases</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Num_of_Returns</th>\n",
       "      <th>Num_of_Support_Contacts</th>\n",
       "      <th>Satisfaction_Score</th>\n",
       "      <th>Last_Purchase_Days_Ago</th>\n",
       "      <th>Email_Opt_In</th>\n",
       "      <th>Promotion_Response</th>\n",
       "      <th>Target_Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>63</td>\n",
       "      <td>Female</td>\n",
       "      <td>175.74</td>\n",
       "      <td>8627.92</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>178.15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>271</td>\n",
       "      <td>True</td>\n",
       "      <td>Unsubscribed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>Other</td>\n",
       "      <td>158.10</td>\n",
       "      <td>7785.70</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>464.56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>False</td>\n",
       "      <td>Unsubscribed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>362</td>\n",
       "      <td>64</td>\n",
       "      <td>Other</td>\n",
       "      <td>34.04</td>\n",
       "      <td>3077.20</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>201.44</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>Ignored</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>564</td>\n",
       "      <td>58</td>\n",
       "      <td>Other</td>\n",
       "      <td>105.79</td>\n",
       "      <td>4066.51</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>312.07</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>True</td>\n",
       "      <td>Unsubscribed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>706</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>177.54</td>\n",
       "      <td>4804.62</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>454.01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>292</td>\n",
       "      <td>False</td>\n",
       "      <td>Responded</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Customer_ID  Age  Gender  Annual_Income  Total_Spend  Years_as_Customer  \\\n",
       "581          582   63  Female         175.74      8627.92                  8   \n",
       "75            76   56   Other         158.10      7785.70                  1   \n",
       "361          362   64   Other          34.04      3077.20                  2   \n",
       "563          564   58   Other         105.79      4066.51                 10   \n",
       "705          706   23  Female         177.54      4804.62                 18   \n",
       "\n",
       "     Num_of_Purchases  Average_Transaction_Amount  Num_of_Returns  \\\n",
       "581                46                      178.15               2   \n",
       "75                 39                      464.56               0   \n",
       "361                 9                      201.44               9   \n",
       "563                52                      312.07               8   \n",
       "705                43                      454.01               5   \n",
       "\n",
       "     Num_of_Support_Contacts  Satisfaction_Score  Last_Purchase_Days_Ago  \\\n",
       "581                        2                   4                     271   \n",
       "75                         2                   1                     267   \n",
       "361                        1                   4                     227   \n",
       "563                        0                   1                     101   \n",
       "705                        0                   5                     292   \n",
       "\n",
       "     Email_Opt_In Promotion_Response  Target_Churn  \n",
       "581          True       Unsubscribed          True  \n",
       "75          False       Unsubscribed          True  \n",
       "361         False            Ignored          True  \n",
       "563          True       Unsubscribed          True  \n",
       "705         False          Responded         False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ec0951-f368-4bef-be08-b19cde37db56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Satisfaction_Score\n",
       "3    219\n",
       "4    204\n",
       "1    202\n",
       "2    192\n",
       "5    183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Satisfaction_Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b06885f-6d0c-4690-a429-2e1273acc967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Total_Spend</th>\n",
       "      <th>Years_as_Customer</th>\n",
       "      <th>Num_of_Purchases</th>\n",
       "      <th>Average_Transaction_Amount</th>\n",
       "      <th>Num_of_Returns</th>\n",
       "      <th>Num_of_Support_Contacts</th>\n",
       "      <th>Satisfaction_Score</th>\n",
       "      <th>Last_Purchase_Days_Ago</th>\n",
       "      <th>Email_Opt_In</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_Other</th>\n",
       "      <th>Promotion_Response_Responded</th>\n",
       "      <th>Promotion_Response_Unsubscribed</th>\n",
       "      <th>Target_Churn_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>68</td>\n",
       "      <td>172.52</td>\n",
       "      <td>8849.87</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>322.94</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>310</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>45</td>\n",
       "      <td>54.51</td>\n",
       "      <td>1877.05</td>\n",
       "      <td>17</td>\n",
       "      <td>64</td>\n",
       "      <td>11.84</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>45</td>\n",
       "      <td>89.76</td>\n",
       "      <td>9342.64</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>45.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>59</td>\n",
       "      <td>194.28</td>\n",
       "      <td>648.03</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>295.58</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>275</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>51</td>\n",
       "      <td>165.10</td>\n",
       "      <td>1693.01</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>248.53</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>349</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Annual_Income  Total_Spend  Years_as_Customer  Num_of_Purchases  \\\n",
       "266   68         172.52      8849.87                 16                88   \n",
       "462   45          54.51      1877.05                 17                64   \n",
       "962   45          89.76      9342.64                  1                24   \n",
       "800   59         194.28       648.03                  8                28   \n",
       "459   51         165.10      1693.01                 11                31   \n",
       "\n",
       "     Average_Transaction_Amount  Num_of_Returns  Num_of_Support_Contacts  \\\n",
       "266                      322.94               3                        3   \n",
       "462                       11.84               3                        4   \n",
       "962                       45.07               1                        1   \n",
       "800                      295.58               7                        4   \n",
       "459                      248.53               7                        1   \n",
       "\n",
       "     Satisfaction_Score  Last_Purchase_Days_Ago  Email_Opt_In  Gender_Male  \\\n",
       "266                   1                     310         False            0   \n",
       "462                   3                     154         False            1   \n",
       "962                   3                      72          True            0   \n",
       "800                   2                     275          True            0   \n",
       "459                   2                     349         False            1   \n",
       "\n",
       "     Gender_Other  Promotion_Response_Responded  \\\n",
       "266             0                             1   \n",
       "462             0                             0   \n",
       "962             0                             1   \n",
       "800             1                             0   \n",
       "459             0                             0   \n",
       "\n",
       "     Promotion_Response_Unsubscribed  Target_Churn_True  \n",
       "266                                0                  1  \n",
       "462                                0                  0  \n",
       "962                                0                  0  \n",
       "800                                0                  1  \n",
       "459                                1                  0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Gender\",\"Promotion_Response\",\"Target_Churn\"], drop_first=True, dtype=int)\n",
    "df = df.drop(columns = \"Customer_ID\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2b1018-76b4-47c5-ac25-de9f002b8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Email_Opt_In\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f0c34b-8c79-444f-b672-a9dfb66e6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Age                              1000 non-null   int64  \n",
      " 1   Annual_Income                    1000 non-null   float64\n",
      " 2   Total_Spend                      1000 non-null   float64\n",
      " 3   Years_as_Customer                1000 non-null   int64  \n",
      " 4   Num_of_Purchases                 1000 non-null   int64  \n",
      " 5   Average_Transaction_Amount       1000 non-null   float64\n",
      " 6   Num_of_Returns                   1000 non-null   int64  \n",
      " 7   Num_of_Support_Contacts          1000 non-null   int64  \n",
      " 8   Satisfaction_Score               1000 non-null   int64  \n",
      " 9   Last_Purchase_Days_Ago           1000 non-null   int64  \n",
      " 10  Gender_Male                      1000 non-null   int32  \n",
      " 11  Gender_Other                     1000 non-null   int32  \n",
      " 12  Promotion_Response_Responded     1000 non-null   int32  \n",
      " 13  Promotion_Response_Unsubscribed  1000 non-null   int32  \n",
      " 14  Target_Churn_True                1000 non-null   int32  \n",
      "dtypes: float64(3), int32(5), int64(7)\n",
      "memory usage: 97.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5775cdf9-aacb-44eb-99c7-c10629cdd66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x3200 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of features\n",
    "features = ['Annual_Income', 'Age', 'Years_as_Customer', 'Num_of_Purchases', 'Annual_Income','Average_Transaction_Amount','Num_of_Returns','Last_Purchase_Days_Ago']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(features), ncols=1, figsize=(8, 4 * len(features)))\n",
    "\n",
    "# If only one subplot, wrap in list to make it iterable\n",
    "if len(features) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop and plot\n",
    "for i, col in enumerate(features):\n",
    "    sns.boxplot(x=df[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot of {col}', fontsize=14)\n",
    "    axes[i].set_xlabel(col, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a006ea0c-cbc9-421a-ba31-806b55bcd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='Target_Churn_True')\n",
    "y = df['Target_Churn_True']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cff43eb0-283e-4070-b92e-396149304aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba399227-ff8c-4b8b-b65c-d43828f17ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\n",
    "        \"RandomForest\", \"LogisticRegression\", \"DecisionTree\",\n",
    "        \"KNN\", \"XGBoost\", \"LightGBM\", \"CatBoost\", \"AdaBoost\"\n",
    "    ])\n",
    "\n",
    "    if classifier_name == \"RandomForest\":\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int(\"rf_n_estimators\", 50, 300),\n",
    "            max_depth=trial.suggest_int(\"rf_max_depth\", 2, 32, log=True),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"LogisticRegression\":\n",
    "        clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                C=trial.suggest_float(\"lr_C\", 1e-3, 1e2, log=True),\n",
    "                solver=\"liblinear\",\n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"DecisionTree\":\n",
    "        clf = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"dt_max_depth\", 2, 32, log=True),\n",
    "            min_samples_split=trial.suggest_int(\"dt_min_samples_split\", 2, 20),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"KNN\":\n",
    "        clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            KNeighborsClassifier(n_neighbors=trial.suggest_int(\"knn_n_neighbors\", 3, 15))\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"XGBoost\":\n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=trial.suggest_int(\"xgb_n_estimators\", 50, 300),\n",
    "            max_depth=trial.suggest_int(\"xgb_max_depth\", 3, 12),\n",
    "            learning_rate=trial.suggest_float(\"xgb_learning_rate\", 0.01, 0.3),\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"LightGBM\":\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=trial.suggest_int(\"lgb_n_estimators\", 50, 300),\n",
    "            max_depth=trial.suggest_int(\"lgb_max_depth\", 3, 12),\n",
    "            learning_rate=trial.suggest_float(\"lgb_learning_rate\", 0.01, 0.3),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"CatBoost\":\n",
    "        clf = CatBoostClassifier(\n",
    "            iterations=trial.suggest_int(\"cat_iterations\", 50, 300),\n",
    "            depth=trial.suggest_int(\"cat_depth\", 3, 10),\n",
    "            learning_rate=trial.suggest_float(\"cat_learning_rate\", 0.01, 0.3),\n",
    "            verbose=0,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    elif classifier_name == \"AdaBoost\":\n",
    "        clf = AdaBoostClassifier(\n",
    "            n_estimators=trial.suggest_int(\"ada_n_estimators\", 50, 300),\n",
    "            learning_rate=trial.suggest_float(\"ada_learning_rate\", 0.01, 1.0),\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3, scoring=\"accuracy\").mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2974709f-2b83-4cfb-b512-a150a0439216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:33:53,314] A new study created in memory with name: no-name-1f004eb8-0ff4-4dab-ba8c-478779838baa\n",
      "[I 2025-04-06 16:34:01,503] Trial 0 finished with value: 0.5187594454300545 and parameters: {'classifier': 'LightGBM', 'lgb_n_estimators': 287, 'lgb_max_depth': 3, 'lgb_learning_rate': 0.21145805258545813}. Best is trial 0 with value: 0.5187594454300545.\n",
      "[I 2025-04-06 16:34:04,602] Trial 1 finished with value: 0.5250110294462749 and parameters: {'classifier': 'LogisticRegression', 'lr_C': 6.315150048087754}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:07,894] Trial 2 finished with value: 0.5012108923995382 and parameters: {'classifier': 'KNN', 'knn_n_neighbors': 12}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:11,005] Trial 3 finished with value: 0.5250110294462749 and parameters: {'classifier': 'LogisticRegression', 'lr_C': 6.962850702479959}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:11,449] Trial 4 finished with value: 0.5099687420799189 and parameters: {'classifier': 'XGBoost', 'xgb_n_estimators': 93, 'xgb_max_depth': 10, 'xgb_learning_rate': 0.01633841795697563}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:11,604] Trial 5 finished with value: 0.5187876057184159 and parameters: {'classifier': 'DecisionTree', 'dt_max_depth': 13, 'dt_min_samples_split': 15}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:11,642] Trial 6 finished with value: 0.5250110294462749 and parameters: {'classifier': 'LogisticRegression', 'lr_C': 0.8542375018393148}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:32,817] Trial 7 finished with value: 0.5000375470511486 and parameters: {'classifier': 'CatBoost', 'cat_iterations': 288, 'cat_depth': 10, 'cat_learning_rate': 0.08853829555041197}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:33,078] Trial 8 finished with value: 0.5200501253132832 and parameters: {'classifier': 'DecisionTree', 'dt_max_depth': 26, 'dt_min_samples_split': 20}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:33,525] Trial 9 finished with value: 0.5062421972534332 and parameters: {'classifier': 'AdaBoost', 'ada_n_estimators': 74, 'ada_learning_rate': 0.6912598353085095}. Best is trial 1 with value: 0.5250110294462749.\n",
      "[I 2025-04-06 16:34:34,184] Trial 10 finished with value: 0.5312626134624951 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 113, 'rf_max_depth': 15}. Best is trial 10 with value: 0.5312626134624951.\n",
      "[I 2025-04-06 16:34:35,004] Trial 11 finished with value: 0.5350267053401293 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 104, 'rf_max_depth': 17}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:35,609] Trial 12 finished with value: 0.5187594454300545 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 105, 'rf_max_depth': 16}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:36,159] Trial 13 finished with value: 0.5200219650249219 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 109, 'rf_max_depth': 16}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:36,844] Trial 14 finished with value: 0.5200266584063155 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 138, 'rf_max_depth': 16}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:37,734] Trial 15 finished with value: 0.5337594923638685 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 250, 'rf_max_depth': 2}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:38,694] Trial 16 finished with value: 0.534998545051768 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 255, 'rf_max_depth': 2}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:40,146] Trial 17 finished with value: 0.516210939333352 and parameters: {'classifier': 'AdaBoost', 'ada_n_estimators': 291, 'ada_learning_rate': 0.08678965974194125}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:41,983] Trial 18 finished with value: 0.5225188439262952 and parameters: {'classifier': 'CatBoost', 'cat_iterations': 53, 'cat_depth': 3, 'cat_learning_rate': 0.29228848720452283}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:42,072] Trial 19 finished with value: 0.5275126017290418 and parameters: {'classifier': 'KNN', 'knn_n_neighbors': 3}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:42,342] Trial 20 finished with value: 0.5150329006035689 and parameters: {'classifier': 'XGBoost', 'xgb_n_estimators': 299, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.297934487632766}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:43,274] Trial 21 finished with value: 0.5350032384331616 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 262, 'rf_max_depth': 2}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:44,260] Trial 22 finished with value: 0.5337547989824749 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 261, 'rf_max_depth': 2}. Best is trial 11 with value: 0.5350267053401293.\n",
      "[I 2025-04-06 16:34:45,013] Trial 23 finished with value: 0.5375282776228962 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 202, 'rf_max_depth': 4}. Best is trial 23 with value: 0.5375282776228962.\n",
      "[I 2025-04-06 16:34:45,228] Trial 24 finished with value: 0.5075047168483006 and parameters: {'classifier': 'LightGBM', 'lgb_n_estimators': 93, 'lgb_max_depth': 12, 'lgb_learning_rate': 0.02735824367876316}. Best is trial 23 with value: 0.5375282776228962.\n",
      "[I 2025-04-06 16:34:46,062] Trial 25 finished with value: 0.5325251330573626 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 192, 'rf_max_depth': 5}. Best is trial 23 with value: 0.5375282776228962.\n",
      "[I 2025-04-06 16:34:46,321] Trial 26 finished with value: 0.5362469845024548 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 51, 'rf_max_depth': 5}. Best is trial 23 with value: 0.5375282776228962.\n",
      "[I 2025-04-06 16:34:46,584] Trial 27 finished with value: 0.5362469845024548 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 51, 'rf_max_depth': 5}. Best is trial 23 with value: 0.5375282776228962.\n",
      "[I 2025-04-06 16:34:46,830] Trial 28 finished with value: 0.5412454356865948 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 50, 'rf_max_depth': 5}. Best is trial 28 with value: 0.5412454356865948.\n",
      "[I 2025-04-06 16:34:50,027] Trial 29 finished with value: 0.5150282072221753 and parameters: {'classifier': 'LightGBM', 'lgb_n_estimators': 259, 'lgb_max_depth': 7, 'lgb_learning_rate': 0.2914765328205091}. Best is trial 28 with value: 0.5412454356865948.\n",
      "[I 2025-04-06 16:34:50,574] Trial 30 finished with value: 0.4888203655205429 and parameters: {'classifier': 'XGBoost', 'xgb_n_estimators': 239, 'xgb_max_depth': 12, 'xgb_learning_rate': 0.15553749290428628}. Best is trial 28 with value: 0.5412454356865948.\n",
      "[I 2025-04-06 16:34:50,851] Trial 31 finished with value: 0.5450142209456225 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 56, 'rf_max_depth': 5}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:51,110] Trial 32 finished with value: 0.5225563909774437 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 50, 'rf_max_depth': 4}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:51,189] Trial 33 finished with value: 0.49125623046379996 and parameters: {'classifier': 'KNN', 'knn_n_neighbors': 15}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:52,065] Trial 34 finished with value: 0.5300000938676279 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 200, 'rf_max_depth': 8}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:52,108] Trial 35 finished with value: 0.5225141505449016 and parameters: {'classifier': 'LogisticRegression', 'lr_C': 0.0012025456768148019}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:52,150] Trial 36 finished with value: 0.516210939333352 and parameters: {'classifier': 'DecisionTree', 'dt_max_depth': 2, 'dt_min_samples_split': 2}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:53,185] Trial 37 finished with value: 0.5274750546778932 and parameters: {'classifier': 'AdaBoost', 'ada_n_estimators': 214, 'ada_learning_rate': 0.9713009904238596}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:56,049] Trial 38 finished with value: 0.5062281171092525 and parameters: {'classifier': 'LightGBM', 'lgb_n_estimators': 62, 'lgb_max_depth': 12, 'lgb_learning_rate': 0.014969386026950249}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:56,567] Trial 39 finished with value: 0.5225423108332629 and parameters: {'classifier': 'CatBoost', 'cat_iterations': 157, 'cat_depth': 6, 'cat_learning_rate': 0.0335214403779959}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:56,612] Trial 40 finished with value: 0.5125266349394084 and parameters: {'classifier': 'LogisticRegression', 'lr_C': 0.006668306645402687}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:56,847] Trial 41 finished with value: 0.5225563909774437 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 50, 'rf_max_depth': 4}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:57,193] Trial 42 finished with value: 0.5175110059793679 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 69, 'rf_max_depth': 6}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:57,557] Trial 43 finished with value: 0.5050219180911079 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 76, 'rf_max_depth': 8}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:57,868] Trial 44 finished with value: 0.5262923225667164 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 73, 'rf_max_depth': 4}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:57,917] Trial 45 finished with value: 0.516210939333352 and parameters: {'classifier': 'DecisionTree', 'dt_max_depth': 2, 'dt_min_samples_split': 4}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:58,717] Trial 46 finished with value: 0.5287610411797283 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 222, 'rf_max_depth': 3}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:58,972] Trial 47 finished with value: 0.5124937812696536 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 50, 'rf_max_depth': 6}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:34:59,061] Trial 48 finished with value: 0.5112781954887219 and parameters: {'classifier': 'KNN', 'knn_n_neighbors': 6}. Best is trial 31 with value: 0.5450142209456225.\n",
      "[I 2025-04-06 16:35:00,164] Trial 49 finished with value: 0.5337594923638684 and parameters: {'classifier': 'RandomForest', 'rf_n_estimators': 298, 'rf_max_depth': 3}. Best is trial 31 with value: 0.5450142209456225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Trial:\n",
      "Accuracy: 0.5450142209456225\n",
      "Params:\n",
      "  classifier: RandomForest\n",
      "  rf_n_estimators: 56\n",
      "  rf_max_depth: 5\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best result\n",
    "print(\"✅ Best Trial:\")\n",
    "print(f\"Accuracy: {study.best_trial.value}\")\n",
    "print(\"Params:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640c071-3706-4462-a4d6-fd2fa836e4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b5423-1a30-4dae-a722-00f6fe97a954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1fe141f-782b-413c-b1c9-778bcd9f077d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 00:16:59,533] A new study created in memory with name: no-name-cf90d070-b233-4c2a-bb89-3e0681724c08\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:16:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:00,119] Trial 0 finished with value: 0.495 and parameters: {'n_estimators': 650, 'learning_rate': 0.10496765501152516, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.7615334098346671, 'colsample_bytree': 0.7872812998795795, 'gamma': 0.6238741572012468, 'lambda': 3.093735571940277, 'alpha': 4.307704729952944}. Best is trial 0 with value: 0.495.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:00,765] Trial 1 finished with value: 0.49 and parameters: {'n_estimators': 900, 'learning_rate': 0.03510616441379435, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.780312628074465, 'colsample_bytree': 0.5670789477128779, 'gamma': 4.380274286864719, 'lambda': 0.3422694998656184, 'alpha': 0.7445800615830567}. Best is trial 1 with value: 0.49.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:01,025] Trial 2 finished with value: 0.48 and parameters: {'n_estimators': 250, 'learning_rate': 0.07606416541463963, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.7884318229684824, 'colsample_bytree': 0.6263269765623736, 'gamma': 4.189251829864179, 'lambda': 3.6268326993319357, 'alpha': 0.635361384442541}. Best is trial 2 with value: 0.48.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:01,230] Trial 3 finished with value: 0.52 and parameters: {'n_estimators': 150, 'learning_rate': 0.14385291852873616, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.5465938967128737, 'colsample_bytree': 0.8616556631091625, 'gamma': 3.9653028990301085, 'lambda': 1.1564701314309627, 'alpha': 0.37428155535478735}. Best is trial 2 with value: 0.48.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:01,773] Trial 4 finished with value: 0.53 and parameters: {'n_estimators': 600, 'learning_rate': 0.016725230237952828, 'max_depth': 12, 'min_child_weight': 9, 'subsample': 0.7462391778031168, 'colsample_bytree': 0.8509794296706215, 'gamma': 2.914382811001915, 'lambda': 3.1962025064726625, 'alpha': 0.5848453564384154}. Best is trial 2 with value: 0.48.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:02,177] Trial 5 finished with value: 0.47 and parameters: {'n_estimators': 500, 'learning_rate': 0.03274896063107572, 'max_depth': 14, 'min_child_weight': 7, 'subsample': 0.8826658167090649, 'colsample_bytree': 0.6242130282081204, 'gamma': 2.9730672398644047, 'lambda': 1.209921030745642, 'alpha': 4.00563771422329}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:02,530] Trial 6 finished with value: 0.47 and parameters: {'n_estimators': 450, 'learning_rate': 0.013997375759574085, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.601265399272056, 'colsample_bytree': 0.65719385801818, 'gamma': 4.2253123390279965, 'lambda': 1.5569485000573136, 'alpha': 3.421565156432605}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:03,010] Trial 7 finished with value: 0.51 and parameters: {'n_estimators': 650, 'learning_rate': 0.2790197353038364, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.6119796416019725, 'colsample_bytree': 0.8876658024339873, 'gamma': 4.088447918859389, 'lambda': 4.068313554500811, 'alpha': 1.3298468458912727}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:03,238] Trial 8 finished with value: 0.47 and parameters: {'n_estimators': 250, 'learning_rate': 0.023267397958230115, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7253635111041482, 'colsample_bytree': 0.7620411020735061, 'gamma': 4.965373310794085, 'lambda': 2.3403649462016825, 'alpha': 4.7064219357500034}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:03,366] Trial 9 finished with value: 0.52 and parameters: {'n_estimators': 100, 'learning_rate': 0.1712212777081871, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.6212224477168, 'colsample_bytree': 0.606474427371245, 'gamma': 2.51419705484029, 'lambda': 4.794470151451685, 'alpha': 4.783246248986676}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:04,175] Trial 10 finished with value: 0.48 and parameters: {'n_estimators': 1000, 'learning_rate': 0.03891355323943886, 'max_depth': 15, 'min_child_weight': 6, 'subsample': 0.9879720694718841, 'colsample_bytree': 0.5022062969332562, 'gamma': 1.1570382129445838, 'lambda': 0.11486909023632985, 'alpha': 2.5296354131056704}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:04,639] Trial 11 finished with value: 0.47 and parameters: {'n_estimators': 450, 'learning_rate': 0.010685897689323102, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.932748057582816, 'colsample_bytree': 0.6826302918114039, 'gamma': 3.087066306936159, 'lambda': 1.5258647903329567, 'alpha': 3.446784725058218}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:05,143] Trial 12 finished with value: 0.485 and parameters: {'n_estimators': 450, 'learning_rate': 0.010994998168134484, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.8898897944601405, 'colsample_bytree': 0.6836863672324186, 'gamma': 1.8544702411085858, 'lambda': 1.5765640454219831, 'alpha': 3.5407628439099184}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:05,564] Trial 13 finished with value: 0.47 and parameters: {'n_estimators': 450, 'learning_rate': 0.02056943069170384, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.8665557906146159, 'colsample_bytree': 0.9727540350007595, 'gamma': 3.2715521737414894, 'lambda': 2.2216815063701842, 'alpha': 3.2662394975591433}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:06,030] Trial 14 finished with value: 0.475 and parameters: {'n_estimators': 350, 'learning_rate': 0.04862363392001046, 'max_depth': 12, 'min_child_weight': 10, 'subsample': 0.5014566865559501, 'colsample_bytree': 0.6869191850972036, 'gamma': 1.9558270003554366, 'lambda': 0.8368654668450806, 'alpha': 2.330122675769011}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:06,680] Trial 15 finished with value: 0.495 and parameters: {'n_estimators': 800, 'learning_rate': 0.027179332895904802, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.6626645692196882, 'colsample_bytree': 0.523328550615993, 'gamma': 3.5184274123413086, 'lambda': 1.8779754318034194, 'alpha': 4.04825700445361}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:07,230] Trial 16 finished with value: 0.47 and parameters: {'n_estimators': 550, 'learning_rate': 0.015364686408831678, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.8400863040905409, 'colsample_bytree': 0.6198647906768427, 'gamma': 4.944952403976659, 'lambda': 0.7961950606789017, 'alpha': 2.706839998627413}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:07,949] Trial 17 finished with value: 0.51 and parameters: {'n_estimators': 750, 'learning_rate': 0.052529059274985024, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6877261297707046, 'colsample_bytree': 0.7210519297599468, 'gamma': 2.2176408099222, 'lambda': 2.781959869418282, 'alpha': 1.8267789646903696}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:08,272] Trial 18 finished with value: 0.47 and parameters: {'n_estimators': 300, 'learning_rate': 0.029613844545380876, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.9732849910696025, 'colsample_bytree': 0.5720043126991546, 'gamma': 3.5915022728646795, 'lambda': 1.1984969081884067, 'alpha': 3.9921764138713423}. Best is trial 5 with value: 0.47.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:08,950] Trial 19 finished with value: 0.45499999999999996 and parameters: {'n_estimators': 400, 'learning_rate': 0.07170231618630811, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.8248447339566801, 'colsample_bytree': 0.8081394537746507, 'gamma': 0.06668328377714472, 'lambda': 2.029445628531718, 'alpha': 3.007530029853701}. Best is trial 19 with value: 0.45499999999999996.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:09,475] Trial 20 finished with value: 0.43999999999999995 and parameters: {'n_estimators': 350, 'learning_rate': 0.07647100670071537, 'max_depth': 14, 'min_child_weight': 4, 'subsample': 0.8177342009294859, 'colsample_bytree': 0.807329670005123, 'gamma': 0.2535619560633745, 'lambda': 2.2523391409696965, 'alpha': 2.9409775819481117}. Best is trial 20 with value: 0.43999999999999995.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:10,063] Trial 21 finished with value: 0.475 and parameters: {'n_estimators': 350, 'learning_rate': 0.07976427072667587, 'max_depth': 14, 'min_child_weight': 4, 'subsample': 0.8409497546754305, 'colsample_bytree': 0.8028915177601659, 'gamma': 0.09892829576671075, 'lambda': 2.056637805015007, 'alpha': 2.9319352048806397}. Best is trial 20 with value: 0.43999999999999995.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:10,771] Trial 22 finished with value: 0.45499999999999996 and parameters: {'n_estimators': 500, 'learning_rate': 0.07149679864048475, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.913170527831269, 'colsample_bytree': 0.80644439457308, 'gamma': 0.12297745087403476, 'lambda': 2.7188304318424956, 'alpha': 1.9879970202936241}. Best is trial 20 with value: 0.43999999999999995.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:11,438] Trial 23 finished with value: 0.42500000000000004 and parameters: {'n_estimators': 350, 'learning_rate': 0.07223401884248226, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.8160444768128997, 'colsample_bytree': 0.9297107555057739, 'gamma': 0.07868373642976581, 'lambda': 2.7083721180379863, 'alpha': 1.9716772821796558}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:11,762] Trial 24 finished with value: 0.475 and parameters: {'n_estimators': 200, 'learning_rate': 0.10128978895529171, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.8248228738383001, 'colsample_bytree': 0.9436330749892833, 'gamma': 0.7969078648715274, 'lambda': 3.5446813104503403, 'alpha': 1.5506879444405368}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:12,189] Trial 25 finished with value: 0.515 and parameters: {'n_estimators': 350, 'learning_rate': 0.15000129945904556, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.7955328515328686, 'colsample_bytree': 0.9160175418986204, 'gamma': 1.3019435795645316, 'lambda': 2.5526003230984746, 'alpha': 2.0452743786498493}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:12,651] Trial 26 finished with value: 0.495 and parameters: {'n_estimators': 350, 'learning_rate': 0.09894675656198232, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.817312135611033, 'colsample_bytree': 0.9836759544715724, 'gamma': 0.5432799751015223, 'lambda': 3.0463770242530153, 'alpha': 2.9771746919482527}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:13,081] Trial 27 finished with value: 0.46499999999999997 and parameters: {'n_estimators': 200, 'learning_rate': 0.06300818810152532, 'max_depth': 11, 'min_child_weight': 4, 'subsample': 0.7212489812407165, 'colsample_bytree': 0.8392800248311089, 'gamma': 0.004348172766595826, 'lambda': 1.8531969697016155, 'alpha': 1.3614466957618772}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:13,489] Trial 28 finished with value: 0.49 and parameters: {'n_estimators': 400, 'learning_rate': 0.20103417721509378, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.9542424297896732, 'colsample_bytree': 0.9103902041946969, 'gamma': 1.069542970030694, 'lambda': 4.128733713390821, 'alpha': 2.2578063222007065}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:14,151] Trial 29 finished with value: 0.48 and parameters: {'n_estimators': 550, 'learning_rate': 0.12505338344336744, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.7610851255434665, 'colsample_bytree': 0.757870303109377, 'gamma': 0.5145931127224599, 'lambda': 2.9227519735421885, 'alpha': 1.005746052390442}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:14,510] Trial 30 finished with value: 0.49 and parameters: {'n_estimators': 250, 'learning_rate': 0.045050997700293846, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8639756339625004, 'colsample_bytree': 0.8295353614959451, 'gamma': 1.4646257922755468, 'lambda': 3.333164201530116, 'alpha': 0.05175393337201184}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:15,091] Trial 31 finished with value: 0.44999999999999996 and parameters: {'n_estimators': 500, 'learning_rate': 0.0683321688750615, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.920332676045486, 'colsample_bytree': 0.7933168001539772, 'gamma': 0.29408371860643145, 'lambda': 2.6395709140249553, 'alpha': 1.741152631382929}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:15,547] Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 400, 'learning_rate': 0.08959629660733469, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.9023263266305626, 'colsample_bytree': 0.7849058261329647, 'gamma': 0.40708690337119124, 'lambda': 2.507590430384401, 'alpha': 2.8859887666331163}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:15,969] Trial 33 finished with value: 0.48 and parameters: {'n_estimators': 300, 'learning_rate': 0.06061490985263541, 'max_depth': 14, 'min_child_weight': 1, 'subsample': 0.7937563707511155, 'colsample_bytree': 0.8784980673170902, 'gamma': 0.8501062017261244, 'lambda': 2.069948092962456, 'alpha': 1.7174988232482682}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:16,689] Trial 34 finished with value: 0.485 and parameters: {'n_estimators': 700, 'learning_rate': 0.06857280321183569, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.9343013171079311, 'colsample_bytree': 0.7118210541376139, 'gamma': 0.3233509296242474, 'lambda': 2.432152315152435, 'alpha': 1.0268167298864672}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:17,273] Trial 35 finished with value: 0.505 and parameters: {'n_estimators': 600, 'learning_rate': 0.04064370452788956, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.8594051635398692, 'colsample_bytree': 0.7402694482603772, 'gamma': 0.882324890180102, 'lambda': 3.9386269847956252, 'alpha': 2.525367302653005}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:17,755] Trial 36 finished with value: 0.47 and parameters: {'n_estimators': 500, 'learning_rate': 0.12314042138144542, 'max_depth': 13, 'min_child_weight': 3, 'subsample': 0.7782196919589962, 'colsample_bytree': 0.8213809533819364, 'gamma': 1.6124018371302382, 'lambda': 3.3027108935350755, 'alpha': 2.1883066892725127}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:18,311] Trial 37 finished with value: 0.51 and parameters: {'n_estimators': 400, 'learning_rate': 0.0864423353183642, 'max_depth': 15, 'min_child_weight': 2, 'subsample': 0.7396485933873755, 'colsample_bytree': 0.7738054573183226, 'gamma': 0.2560813718218126, 'lambda': 1.8265018068461698, 'alpha': 3.7727253795957654}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:18,880] Trial 38 finished with value: 0.505 and parameters: {'n_estimators': 600, 'learning_rate': 0.05742297963912305, 'max_depth': 14, 'min_child_weight': 3, 'subsample': 0.8268904465395954, 'colsample_bytree': 0.9276267534358139, 'gamma': 0.7892262315546463, 'lambda': 2.677636212743753, 'alpha': 3.125517649331925}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:19,288] Trial 39 finished with value: 0.48 and parameters: {'n_estimators': 300, 'learning_rate': 0.0790261840072678, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.8070666444454866, 'colsample_bytree': 0.8735174502362025, 'gamma': 0.5945127303044395, 'lambda': 2.2020621448804047, 'alpha': 2.5894880630534542}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:19,598] Trial 40 finished with value: 0.495 and parameters: {'n_estimators': 150, 'learning_rate': 0.12115230998106678, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7766990462456171, 'colsample_bytree': 0.8528783663601422, 'gamma': 0.27427270522892677, 'lambda': 3.6604321382017098, 'alpha': 4.359520325050096}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:20,339] Trial 41 finished with value: 0.45499999999999996 and parameters: {'n_estimators': 500, 'learning_rate': 0.06990924381299395, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.9132826258200415, 'colsample_bytree': 0.8006451123421259, 'gamma': 0.05341449194634472, 'lambda': 2.8292483871448786, 'alpha': 1.8900437724523114}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:20,880] Trial 42 finished with value: 0.43500000000000005 and parameters: {'n_estimators': 550, 'learning_rate': 0.055763033315357306, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9978718720172267, 'colsample_bytree': 0.8032630405351842, 'gamma': 0.3107448460023218, 'lambda': 3.1301802208695815, 'alpha': 2.0370180986290047}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:21,492] Trial 43 finished with value: 0.44999999999999996 and parameters: {'n_estimators': 650, 'learning_rate': 0.054409067573532886, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9924467338760166, 'colsample_bytree': 0.742433771974617, 'gamma': 1.0319019242275038, 'lambda': 3.1021211901071624, 'alpha': 1.5504565478463916}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:22,082] Trial 44 finished with value: 0.5 and parameters: {'n_estimators': 650, 'learning_rate': 0.03490935822437754, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9869943506515926, 'colsample_bytree': 0.733029584854573, 'gamma': 1.1657001194999936, 'lambda': 3.097153563381282, 'alpha': 1.572844436652804}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:22,777] Trial 45 finished with value: 0.47 and parameters: {'n_estimators': 700, 'learning_rate': 0.045107996076410875, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.9587426611670048, 'colsample_bytree': 0.7652224537116585, 'gamma': 0.5561804304560927, 'lambda': 3.457980171965024, 'alpha': 1.177262282849669}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:23,490] Trial 46 finished with value: 0.475 and parameters: {'n_estimators': 800, 'learning_rate': 0.052153225237596954, 'max_depth': 11, 'min_child_weight': 1, 'subsample': 0.9423149891555689, 'colsample_bytree': 0.7094632582386086, 'gamma': 0.7311107241438195, 'lambda': 3.69082717288176, 'alpha': 1.6344414532629445}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:24,046] Trial 47 finished with value: 0.51 and parameters: {'n_estimators': 550, 'learning_rate': 0.03959522129379542, 'max_depth': 13, 'min_child_weight': 1, 'subsample': 0.9942705251944228, 'colsample_bytree': 0.7824601543670059, 'gamma': 1.008650455945447, 'lambda': 3.098211508303212, 'alpha': 0.5904336683101116}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:24,675] Trial 48 finished with value: 0.5 and parameters: {'n_estimators': 650, 'learning_rate': 0.09119844309002231, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.9599629811890201, 'colsample_bytree': 0.6520249113282038, 'gamma': 0.3610385213719079, 'lambda': 3.871490955528336, 'alpha': 0.8217876191726646}. Best is trial 23 with value: 0.42500000000000004.\n",
      "C:\\Users\\Utkarsh Rai\\AppData\\Local\\Temp\\ipykernel_8104\\1352721471.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
      "C:\\Users\\Utkarsh Rai\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [00:17:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-16 00:17:25,393] Trial 49 finished with value: 0.49 and parameters: {'n_estimators': 850, 'learning_rate': 0.05914781186439123, 'max_depth': 12, 'min_child_weight': 1, 'subsample': 0.8866604467298891, 'colsample_bytree': 0.9525100843126769, 'gamma': 1.5088860803059574, 'lambda': 2.3155654705702324, 'alpha': 1.3503536543745474}. Best is trial 23 with value: 0.42500000000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 350, 'learning_rate': 0.07223401884248226, 'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.8160444768128997, 'colsample_bytree': 0.9297107555057739, 'gamma': 0.07868373642976581, 'lambda': 2.7083721180379863, 'alpha': 1.9716772821796558}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna to optimize XGBClassifier.\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=50),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0, 5),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 0, 5),\n",
    "        \"objective\": \"binary:logistic\",  # Use 'multi:softmax' for multi-class classification\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False\n",
    "    }\n",
    "\n",
    "    # Train XGBClassifier with suggested parameters\n",
    "    model = xgb.XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    return 1 - accuracy  # Minimize error (maximize accuracy)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")  # Minimize classification error\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get best parameters\n",
    "print(f\"Best parameters: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed64579e-3296-49e4-9f06-ea566b4e2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "# Train the final model with optimized parameters\n",
    "final_model = xgb.XGBClassifier(**best_params, random_state=42)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99c2a544-2f79-4214-9dac-a8a6359001e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_error\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10, 100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 50),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "    }\n",
    "\n",
    "    # Train LightGBM model\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_metric=\"logloss\", eval_set=[(X_test, y_test)], callbacks=[early_stopping(10), log_evaluation(1)])\n",
    "\n",
    "    # Predict & evaluate\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    print(\"Accuracy->\",accuracy)\n",
    "    \n",
    "    return 1 - accuracy  # Optuna minimizes the objective, so we return (1 - accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c42f0ed0-3230-46da-86e2-e236bf2a7679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:48,346] A new study created in memory with name: no-name-62700a2c-47b3-4b82-b260-fb29c7f0d24f\n",
      "[I 2025-04-06 16:37:48,381] Trial 0 finished with value: 0.47 and parameters: {'learning_rate': 0.010788898921593985, 'num_leaves': 72, 'max_depth': 6, 'min_data_in_leaf': 27, 'feature_fraction': 0.6963876576023655, 'bagging_fraction': 0.5834825339178291, 'bagging_freq': 3, 'lambda_l1': 2.1215036984776868e-06, 'lambda_l2': 0.0008030028546050477}. Best is trial 0 with value: 0.47.\n",
      "[I 2025-04-06 16:37:48,430] Trial 1 finished with value: 0.46499999999999997 and parameters: {'learning_rate': 0.05151174594070255, 'num_leaves': 44, 'max_depth': 8, 'min_data_in_leaf': 28, 'feature_fraction': 0.9194791191975287, 'bagging_fraction': 0.7246114019598504, 'bagging_freq': 2, 'lambda_l1': 1.0331689319716999e-05, 'lambda_l2': 0.05012740647991245}. Best is trial 1 with value: 0.46499999999999997.\n",
      "[I 2025-04-06 16:37:48,486] Trial 2 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.01805370103858205, 'num_leaves': 80, 'max_depth': 8, 'min_data_in_leaf': 1, 'feature_fraction': 0.8853507843725604, 'bagging_fraction': 0.9312738466226118, 'bagging_freq': 5, 'lambda_l1': 0.004221128990413145, 'lambda_l2': 6.206098682202228e-08}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,518] Trial 3 finished with value: 0.47 and parameters: {'learning_rate': 0.033435337297951145, 'num_leaves': 25, 'max_depth': 7, 'min_data_in_leaf': 36, 'feature_fraction': 0.865552335427089, 'bagging_fraction': 0.5737103180406167, 'bagging_freq': 2, 'lambda_l1': 1.4884689428098187e-07, 'lambda_l2': 0.0006725302804761294}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,548] Trial 4 finished with value: 0.47 and parameters: {'learning_rate': 0.021975154987706826, 'num_leaves': 26, 'max_depth': 4, 'min_data_in_leaf': 24, 'feature_fraction': 0.5530548713367189, 'bagging_fraction': 0.8997513324272717, 'bagging_freq': 9, 'lambda_l1': 3.7707223318937246, 'lambda_l2': 2.1061033144822738e-07}. Best is trial 2 with value: 0.41500000000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6963876576023655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6963876576023655\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1215036984776868e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1215036984776868e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008030028546050477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008030028546050477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5834825339178291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5834825339178291\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6963876576023655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6963876576023655\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1215036984776868e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1215036984776868e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008030028546050477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008030028546050477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5834825339178291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5834825339178291\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6963876576023655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6963876576023655\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1215036984776868e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1215036984776868e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008030028546050477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008030028546050477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5834825339178291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5834825339178291\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690987\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691081\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691161\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691224\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691559\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691423\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691749\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.691974\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.69221\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.69243\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.692344\tvalid_0's binary_error: 0.475\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.690987\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=27, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=27\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6963876576023655, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6963876576023655\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1215036984776868e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1215036984776868e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0008030028546050477, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0008030028546050477\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5834825339178291, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5834825339178291\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9194791191975287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9194791191975287\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0331689319716999e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0331689319716999e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05012740647991245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05012740647991245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7246114019598504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7246114019598504\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9194791191975287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9194791191975287\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0331689319716999e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0331689319716999e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05012740647991245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05012740647991245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7246114019598504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7246114019598504\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9194791191975287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9194791191975287\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0331689319716999e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0331689319716999e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05012740647991245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05012740647991245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7246114019598504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7246114019598504\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.69248\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.692096\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690145\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689383\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691299\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.692024\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691769\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.692886\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691321\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.690329\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.693805\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.69661\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.697636\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.699257\tvalid_0's binary_error: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.689383\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9194791191975287, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9194791191975287\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0331689319716999e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0331689319716999e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05012740647991245, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05012740647991245\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7246114019598504, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7246114019598504\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8853507843725604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8853507843725604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004221128990413145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004221128990413145\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.206098682202228e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.206098682202228e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312738466226118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312738466226118\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8853507843725604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8853507843725604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004221128990413145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004221128990413145\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.206098682202228e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.206098682202228e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312738466226118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312738466226118\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8853507843725604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8853507843725604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004221128990413145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004221128990413145\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.206098682202228e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.206098682202228e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312738466226118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312738466226118\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689769\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.68911\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687885\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.686981\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.685532\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.685822\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.684516\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.685317\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.68532\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.684558\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.685416\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.685295\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685129\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.685657\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.685581\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.684495\tvalid_0's binary_error: 0.425\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.685822\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8853507843725604, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8853507843725604\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004221128990413145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004221128990413145\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.206098682202228e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.206098682202228e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9312738466226118, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9312738466226118\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.585\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865552335427089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.865552335427089\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4884689428098187e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4884689428098187e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0006725302804761294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006725302804761294\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737103180406167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737103180406167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865552335427089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.865552335427089\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4884689428098187e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4884689428098187e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0006725302804761294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006725302804761294\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737103180406167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737103180406167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865552335427089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.865552335427089\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4884689428098187e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4884689428098187e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0006725302804761294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006725302804761294\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737103180406167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737103180406167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691823\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691825\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.692238\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.693621\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.694041\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.695676\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.696042\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.696391\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.698564\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.699304\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.699421\tvalid_0's binary_error: 0.52\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691823\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=36, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=36\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865552335427089, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.865552335427089\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4884689428098187e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4884689428098187e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0006725302804761294, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006725302804761294\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5737103180406167, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5737103180406167\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5530548713367189, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5530548713367189\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7707223318937246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7707223318937246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1061033144822738e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1061033144822738e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8997513324272717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8997513324272717\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5530548713367189, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5530548713367189\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7707223318937246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7707223318937246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1061033144822738e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1061033144822738e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8997513324272717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8997513324272717\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5530548713367189, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5530548713367189\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7707223318937246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7707223318937246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1061033144822738e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1061033144822738e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8997513324272717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8997513324272717\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690508\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690204\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690053\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690169\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689994\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.68997\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690007\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.690022\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.690198\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.690268\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.690539\tvalid_0's binary_error: 0.475\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.690508\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=24, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=24\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5530548713367189, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5530548713367189\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.7707223318937246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.7707223318937246\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.1061033144822738e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.1061033144822738e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8997513324272717, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8997513324272717\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:48,585] Trial 5 finished with value: 0.475 and parameters: {'learning_rate': 0.16881085989502376, 'num_leaves': 72, 'max_depth': 4, 'min_data_in_leaf': 47, 'feature_fraction': 0.8549464382917076, 'bagging_fraction': 0.9623828214987901, 'bagging_freq': 4, 'lambda_l1': 0.003970060627480018, 'lambda_l2': 2.6445560192611846e-06}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,617] Trial 6 finished with value: 0.47 and parameters: {'learning_rate': 0.01480737101649632, 'num_leaves': 38, 'max_depth': 8, 'min_data_in_leaf': 50, 'feature_fraction': 0.9513667304136431, 'bagging_fraction': 0.6463380582838916, 'bagging_freq': 6, 'lambda_l1': 0.44709376883110247, 'lambda_l2': 0.0013449938700218545}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,656] Trial 7 finished with value: 0.47 and parameters: {'learning_rate': 0.02497023982472431, 'num_leaves': 96, 'max_depth': 8, 'min_data_in_leaf': 46, 'feature_fraction': 0.934138854365355, 'bagging_fraction': 0.5543690613231433, 'bagging_freq': 4, 'lambda_l1': 0.0748853884482519, 'lambda_l2': 5.592375537624636e-08}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,697] Trial 8 finished with value: 0.44999999999999996 and parameters: {'learning_rate': 0.2159416423479994, 'num_leaves': 60, 'max_depth': 6, 'min_data_in_leaf': 32, 'feature_fraction': 0.6461850945319247, 'bagging_fraction': 0.7887912976581525, 'bagging_freq': 2, 'lambda_l1': 1.9554297844976018e-05, 'lambda_l2': 6.959874385400044e-08}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,730] Trial 9 finished with value: 0.47 and parameters: {'learning_rate': 0.015450017358626044, 'num_leaves': 30, 'max_depth': 7, 'min_data_in_leaf': 44, 'feature_fraction': 0.6083569348018565, 'bagging_fraction': 0.6408649995751579, 'bagging_freq': 1, 'lambda_l1': 7.810436526344517, 'lambda_l2': 0.011995819205110522}. Best is trial 2 with value: 0.41500000000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549464382917076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549464382917076\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003970060627480018, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003970060627480018\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6445560192611846e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6445560192611846e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623828214987901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623828214987901\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549464382917076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549464382917076\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003970060627480018, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003970060627480018\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6445560192611846e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6445560192611846e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623828214987901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623828214987901\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549464382917076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549464382917076\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003970060627480018, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003970060627480018\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6445560192611846e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6445560192611846e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623828214987901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623828214987901\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.688393\tvalid_0's binary_error: 0.475\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691154\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.693576\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.693914\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.695444\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.693801\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.694987\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.6916\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.696796\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.699766\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.700502\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.688393\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=47, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=47\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8549464382917076, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8549464382917076\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003970060627480018, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003970060627480018\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6445560192611846e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6445560192611846e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9623828214987901, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9623828214987901\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513667304136431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513667304136431\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.44709376883110247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.44709376883110247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013449938700218545, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013449938700218545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6463380582838916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463380582838916\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513667304136431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513667304136431\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.44709376883110247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.44709376883110247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013449938700218545, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013449938700218545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6463380582838916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463380582838916\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513667304136431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513667304136431\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.44709376883110247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.44709376883110247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013449938700218545, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013449938700218545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6463380582838916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463380582838916\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691453\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691571\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691639\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691618\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.69147\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691359\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691765\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.692065\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.692407\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.692715\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.69298\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691453\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9513667304136431, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9513667304136431\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.44709376883110247, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.44709376883110247\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013449938700218545, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013449938700218545\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6463380582838916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6463380582838916\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] feature_fraction is set=0.934138854365355, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.934138854365355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0748853884482519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0748853884482519\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592375537624636e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.592375537624636e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5543690613231433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5543690613231433\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] feature_fraction is set=0.934138854365355, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.934138854365355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0748853884482519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0748853884482519\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592375537624636e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.592375537624636e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5543690613231433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5543690613231433\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] feature_fraction is set=0.934138854365355, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.934138854365355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0748853884482519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0748853884482519\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592375537624636e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.592375537624636e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5543690613231433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5543690613231433\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691541\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691817\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691853\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691757\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691747\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.692189\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.69234\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.691949\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.692658\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.693404\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.693927\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691541\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] feature_fraction is set=0.934138854365355, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.934138854365355\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0748853884482519, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0748853884482519\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.592375537624636e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.592375537624636e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5543690613231433, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5543690613231433\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461850945319247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461850945319247\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9554297844976018e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9554297844976018e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.959874385400044e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.959874385400044e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7887912976581525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887912976581525\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461850945319247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461850945319247\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9554297844976018e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9554297844976018e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.959874385400044e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.959874385400044e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7887912976581525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887912976581525\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461850945319247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461850945319247\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9554297844976018e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9554297844976018e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.959874385400044e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.959874385400044e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7887912976581525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887912976581525\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690678\tvalid_0's binary_error: 0.465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.685586\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.686238\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691639\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.692235\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687313\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.684853\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.684952\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691585\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696039\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.710226\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.719364\tvalid_0's binary_error: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.685586\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=32, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=32\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6461850945319247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6461850945319247\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.9554297844976018e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9554297844976018e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.959874385400044e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.959874385400044e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7887912976581525, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887912976581525\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6083569348018565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6083569348018565\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810436526344517, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810436526344517\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011995819205110522, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011995819205110522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6408649995751579, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6408649995751579\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6083569348018565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6083569348018565\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810436526344517, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810436526344517\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011995819205110522, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011995819205110522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6408649995751579, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6408649995751579\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6083569348018565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6083569348018565\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810436526344517, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810436526344517\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011995819205110522, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011995819205110522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6408649995751579, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6408649995751579\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691204\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691249\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691275\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691192\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691119\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691166\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691274\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.691214\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691097\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.69103\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.691129\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691204\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=44, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=44\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6083569348018565, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6083569348018565\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.810436526344517, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.810436526344517\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011995819205110522, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011995819205110522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6408649995751579, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6408649995751579\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:48,855] Trial 10 finished with value: 0.44999999999999996 and parameters: {'learning_rate': 0.11670746899516982, 'num_leaves': 99, 'max_depth': 10, 'min_data_in_leaf': 2, 'feature_fraction': 0.7764317081514627, 'bagging_fraction': 0.8464141498563398, 'bagging_freq': 7, 'lambda_l1': 0.0007232922591756126, 'lambda_l2': 2.455310973568742e-05}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:48,967] Trial 11 finished with value: 0.48 and parameters: {'learning_rate': 0.2903746672427923, 'num_leaves': 67, 'max_depth': 5, 'min_data_in_leaf': 6, 'feature_fraction': 0.6911571754412023, 'bagging_fraction': 0.8277713961028669, 'bagging_freq': 8, 'lambda_l1': 1.345504652556669e-05, 'lambda_l2': 1.1315666386610616e-08}. Best is trial 2 with value: 0.41500000000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7764317081514627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7764317081514627\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007232922591756126, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007232922591756126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.455310973568742e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.455310973568742e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8464141498563398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464141498563398\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7764317081514627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7764317081514627\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007232922591756126, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007232922591756126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.455310973568742e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.455310973568742e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8464141498563398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464141498563398\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7764317081514627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7764317081514627\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007232922591756126, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007232922591756126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.455310973568742e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.455310973568742e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8464141498563398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464141498563398\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.695969\tvalid_0's binary_error: 0.48\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.696177\tvalid_0's binary_error: 0.485\n",
      "[3]\tvalid_0's binary_logloss: 0.684413\tvalid_0's binary_error: 0.45\n",
      "[4]\tvalid_0's binary_logloss: 0.694697\tvalid_0's binary_error: 0.445\n",
      "[5]\tvalid_0's binary_logloss: 0.702912\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.705296\tvalid_0's binary_error: 0.465\n",
      "[7]\tvalid_0's binary_logloss: 0.70049\tvalid_0's binary_error: 0.455\n",
      "[8]\tvalid_0's binary_logloss: 0.695435\tvalid_0's binary_error: 0.435\n",
      "[9]\tvalid_0's binary_logloss: 0.702691\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.70004\tvalid_0's binary_error: 0.455\n",
      "[11]\tvalid_0's binary_logloss: 0.709025\tvalid_0's binary_error: 0.48\n",
      "[12]\tvalid_0's binary_logloss: 0.720662\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.723368\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.684413\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7764317081514627, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7764317081514627\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007232922591756126, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007232922591756126\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.455310973568742e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.455310973568742e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8464141498563398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8464141498563398\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Accuracy-> 0.55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6911571754412023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6911571754412023\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.345504652556669e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.345504652556669e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1315666386610616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1315666386610616e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8277713961028669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277713961028669\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6911571754412023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6911571754412023\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.345504652556669e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.345504652556669e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1315666386610616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1315666386610616e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8277713961028669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277713961028669\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6911571754412023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6911571754412023\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.345504652556669e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.345504652556669e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1315666386610616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1315666386610616e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8277713961028669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277713961028669\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691974\tvalid_0's binary_error: 0.48\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.692183\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.697448\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.69566\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.698584\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.694936\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.701025\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.704767\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.697391\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.703349\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.698731\tvalid_0's binary_error: 0.41\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691974\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6911571754412023, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6911571754412023\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.345504652556669e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.345504652556669e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1315666386610616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1315666386610616e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8277713961028669, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8277713961028669\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Accuracy-> 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:49,085] Trial 12 finished with value: 0.46499999999999997 and parameters: {'learning_rate': 0.0882992463409523, 'num_leaves': 59, 'max_depth': 10, 'min_data_in_leaf': 15, 'feature_fraction': 0.7925625802822056, 'bagging_fraction': 0.7644010099495886, 'bagging_freq': 5, 'lambda_l1': 0.005349046037032, 'lambda_l2': 8.295517405698783}. Best is trial 2 with value: 0.41500000000000004.\n",
      "[I 2025-04-06 16:37:49,198] Trial 13 finished with value: 0.43500000000000005 and parameters: {'learning_rate': 0.05336864053842789, 'num_leaves': 84, 'max_depth': 6, 'min_data_in_leaf': 16, 'feature_fraction': 0.649322467908966, 'bagging_fraction': 0.9947591046993814, 'bagging_freq': 10, 'lambda_l1': 1.196639805133162e-08, 'lambda_l2': 1.84324333785838e-06}. Best is trial 2 with value: 0.41500000000000004.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7925625802822056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7925625802822056\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005349046037032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005349046037032\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.295517405698783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.295517405698783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7644010099495886, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7644010099495886\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7925625802822056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7925625802822056\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005349046037032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005349046037032\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.295517405698783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.295517405698783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7644010099495886, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7644010099495886\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7925625802822056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7925625802822056\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005349046037032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005349046037032\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.295517405698783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.295517405698783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7644010099495886, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7644010099495886\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691437\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689898\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.68823\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.68887\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691128\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.692247\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.693912\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.694878\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.693376\tvalid_0's binary_error: 0.525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.693961\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.695286\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.696067\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.697803\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.68823\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7925625802822056, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7925625802822056\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005349046037032, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005349046037032\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.295517405698783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.295517405698783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7644010099495886, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7644010099495886\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.649322467908966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.649322467908966\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.196639805133162e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.196639805133162e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.84324333785838e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.84324333785838e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9947591046993814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947591046993814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.649322467908966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.649322467908966\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.196639805133162e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.196639805133162e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.84324333785838e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.84324333785838e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9947591046993814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947591046993814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.649322467908966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.649322467908966\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.196639805133162e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.196639805133162e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.84324333785838e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.84324333785838e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9947591046993814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947591046993814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.69099\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690423\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.688464\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688341\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.688939\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.688945\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690168\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689561\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.68979\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689226\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.688467\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.689167\tvalid_0's binary_error: 0.46\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.690423\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.649322467908966, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.649322467908966\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.196639805133162e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.196639805133162e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.84324333785838e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.84324333785838e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9947591046993814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947591046993814\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:49,309] Trial 14 finished with value: 0.405 and parameters: {'learning_rate': 0.05373086256786327, 'num_leaves': 85, 'max_depth': 3, 'min_data_in_leaf': 16, 'feature_fraction': 0.54280583533588, 'bagging_fraction': 0.9823744879773261, 'bagging_freq': 10, 'lambda_l1': 2.1249230152570193e-08, 'lambda_l2': 6.814334217130867e-06}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:49,414] Trial 15 finished with value: 0.43500000000000005 and parameters: {'learning_rate': 0.03692011077397685, 'num_leaves': 85, 'max_depth': 3, 'min_data_in_leaf': 11, 'feature_fraction': 0.512847424529314, 'bagging_fraction': 0.923553892088754, 'bagging_freq': 7, 'lambda_l1': 0.0004046381365387947, 'lambda_l2': 1.9847077967215978e-05}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.54280583533588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.54280583533588\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1249230152570193e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1249230152570193e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.814334217130867e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.814334217130867e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9823744879773261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823744879773261\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.54280583533588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.54280583533588\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1249230152570193e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1249230152570193e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.814334217130867e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.814334217130867e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9823744879773261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823744879773261\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.54280583533588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.54280583533588\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1249230152570193e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1249230152570193e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.814334217130867e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.814334217130867e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9823744879773261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823744879773261\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691846\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691527\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690994\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691156\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.690027\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690058\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690105\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689675\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.689819\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689709\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.689697\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.688839\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.68903\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.688833\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.688477\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.688318\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.688083\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.688433\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.688959\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.688766\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.687701\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.687463\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's binary_logloss: 0.685831\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's binary_logloss: 0.685595\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's binary_logloss: 0.685492\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's binary_logloss: 0.68508\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's binary_logloss: 0.685436\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's binary_logloss: 0.684888\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's binary_logloss: 0.685205\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.68485\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's binary_logloss: 0.685177\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's binary_logloss: 0.685527\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's binary_logloss: 0.686189\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's binary_logloss: 0.685653\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's binary_logloss: 0.685595\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.54280583533588, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.54280583533588\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1249230152570193e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1249230152570193e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.814334217130867e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.814334217130867e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9823744879773261, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9823744879773261\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.595\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.512847424529314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.512847424529314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004046381365387947, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004046381365387947\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9847077967215978e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9847077967215978e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923553892088754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.923553892088754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.512847424529314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.512847424529314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004046381365387947, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004046381365387947\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9847077967215978e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9847077967215978e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923553892088754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.923553892088754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.512847424529314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.512847424529314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004046381365387947, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004046381365387947\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9847077967215978e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9847077967215978e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923553892088754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.923553892088754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690726\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689941\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.689246\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688877\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.688626\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.688741\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.688531\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.688113\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.688204\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.688372\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.688715\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.688959\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.68909\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.689\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.689362\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.690298\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.689461\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.689825\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.688113\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.512847424529314, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.512847424529314\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0004046381365387947, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004046381365387947\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9847077967215978e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9847077967215978e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.923553892088754, subsample=1.0 will be ignored. Current value: bagging_fraction=0.923553892088754\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Accuracy-> 0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:49,533] Trial 16 finished with value: 0.41000000000000003 and parameters: {'learning_rate': 0.08453287384235114, 'num_leaves': 85, 'max_depth': 9, 'min_data_in_leaf': 20, 'feature_fraction': 0.8322917490364681, 'bagging_fraction': 0.8900341143593663, 'bagging_freq': 10, 'lambda_l1': 0.03409414313360865, 'lambda_l2': 1.728495521371395e-06}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:49,650] Trial 17 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.08598938159690507, 'num_leaves': 91, 'max_depth': 9, 'min_data_in_leaf': 22, 'feature_fraction': 0.8062573628990684, 'bagging_fraction': 0.8631520058592107, 'bagging_freq': 10, 'lambda_l1': 0.08882782819313341, 'lambda_l2': 3.740096247006446e-05}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8322917490364681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8322917490364681\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03409414313360865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03409414313360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.728495521371395e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.728495521371395e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8900341143593663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8900341143593663\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8322917490364681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8322917490364681\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03409414313360865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03409414313360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.728495521371395e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.728495521371395e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8900341143593663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8900341143593663\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8322917490364681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8322917490364681\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03409414313360865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03409414313360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.728495521371395e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.728495521371395e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8900341143593663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8900341143593663\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.688969\tvalid_0's binary_error: 0.45\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.688948\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690665\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.692886\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.692029\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.698534\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.697142\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.700059\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.703831\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.70693\tvalid_0's binary_error: 0.525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.709221\tvalid_0's binary_error: 0.53\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.707945\tvalid_0's binary_error: 0.51\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.688948\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8322917490364681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8322917490364681\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03409414313360865, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03409414313360865\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.728495521371395e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.728495521371395e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8900341143593663, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8900341143593663\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062573628990684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062573628990684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08882782819313341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08882782819313341\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.740096247006446e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.740096247006446e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8631520058592107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8631520058592107\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062573628990684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062573628990684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08882782819313341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08882782819313341\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.740096247006446e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.740096247006446e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8631520058592107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8631520058592107\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062573628990684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062573628990684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08882782819313341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08882782819313341\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.740096247006446e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.740096247006446e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8631520058592107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8631520058592107\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.687531\tvalid_0's binary_error: 0.465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.6878\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.686502\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689615\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.69036\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690446\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.693665\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.696032\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691436\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696141\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.697884\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.701367\tvalid_0's binary_error: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.6878\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=22, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=22\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8062573628990684, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8062573628990684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08882782819313341, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08882782819313341\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.740096247006446e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.740096247006446e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8631520058592107, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8631520058592107\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:49,775] Trial 18 finished with value: 0.43999999999999995 and parameters: {'learning_rate': 0.07422155255284252, 'num_leaves': 49, 'max_depth': 3, 'min_data_in_leaf': 19, 'feature_fraction': 0.7266987977037169, 'bagging_fraction': 0.9661411965816036, 'bagging_freq': 9, 'lambda_l1': 1.379296868342706e-08, 'lambda_l2': 2.0569654492584703e-06}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:49,879] Trial 19 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.12710587784139807, 'num_leaves': 79, 'max_depth': 9, 'min_data_in_leaf': 11, 'feature_fraction': 0.9831644984417109, 'bagging_fraction': 0.8863035240068112, 'bagging_freq': 9, 'lambda_l1': 5.968435900005118e-07, 'lambda_l2': 0.00010361886409057746}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7266987977037169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7266987977037169\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.379296868342706e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.379296868342706e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0569654492584703e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0569654492584703e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9661411965816036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9661411965816036\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7266987977037169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7266987977037169\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.379296868342706e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.379296868342706e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0569654492584703e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0569654492584703e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9661411965816036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9661411965816036\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7266987977037169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7266987977037169\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.379296868342706e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.379296868342706e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0569654492584703e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0569654492584703e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9661411965816036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9661411965816036\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691302\tvalid_0's binary_error: 0.46\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691282\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690136\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689021\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.68839\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.688618\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.688731\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689342\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.688407\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.688688\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.689582\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.69072\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.691551\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.691037\tvalid_0's binary_error: 0.445\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.689021\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=19, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=19\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7266987977037169, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7266987977037169\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.379296868342706e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.379296868342706e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.0569654492584703e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0569654492584703e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9661411965816036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9661411965816036\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.56\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9831644984417109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9831644984417109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.968435900005118e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.968435900005118e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010361886409057746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010361886409057746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8863035240068112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863035240068112\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9831644984417109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9831644984417109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.968435900005118e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.968435900005118e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010361886409057746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010361886409057746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8863035240068112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863035240068112\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9831644984417109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9831644984417109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.968435900005118e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.968435900005118e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010361886409057746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010361886409057746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8863035240068112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863035240068112\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689205\tvalid_0's binary_error: 0.44\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.685788\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.693607\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.699461\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.703744\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.709354\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.70533\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.708843\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.710489\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.712164\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.713121\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.711615\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.685788\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9831644984417109, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9831644984417109\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.968435900005118e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.968435900005118e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010361886409057746, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010361886409057746\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8863035240068112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863035240068112\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:49,988] Trial 20 finished with value: 0.47 and parameters: {'learning_rate': 0.03883860026596004, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 38, 'feature_fraction': 0.5739669670700769, 'bagging_fraction': 0.5003122501525215, 'bagging_freq': 8, 'lambda_l1': 8.468201972928357e-05, 'lambda_l2': 6.217875037823279e-07}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:50,114] Trial 21 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.06723495409316838, 'num_leaves': 78, 'max_depth': 9, 'min_data_in_leaf': 3, 'feature_fraction': 0.8721790148799835, 'bagging_fraction': 0.9253515948795656, 'bagging_freq': 6, 'lambda_l1': 0.008116806773293541, 'lambda_l2': 1.74505496234732e-08}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5739669670700769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5739669670700769\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.468201972928357e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.468201972928357e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.217875037823279e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.217875037823279e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5003122501525215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5003122501525215\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5739669670700769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5739669670700769\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.468201972928357e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.468201972928357e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.217875037823279e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.217875037823279e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5003122501525215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5003122501525215\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5739669670700769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5739669670700769\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.468201972928357e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.468201972928357e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.217875037823279e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.217875037823279e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5003122501525215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5003122501525215\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691446\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691421\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.692434\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.69158\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691439\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.69274\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.693372\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.694125\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.6933\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.694288\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.694349\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.694949\tvalid_0's binary_error: 0.525\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.691421\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5739669670700769, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5739669670700769\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.468201972928357e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.468201972928357e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.217875037823279e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.217875037823279e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5003122501525215, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5003122501525215\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8721790148799835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8721790148799835\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008116806773293541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008116806773293541\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.74505496234732e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.74505496234732e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253515948795656, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253515948795656\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8721790148799835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8721790148799835\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008116806773293541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008116806773293541\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.74505496234732e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.74505496234732e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253515948795656, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253515948795656\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8721790148799835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8721790148799835\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008116806773293541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008116806773293541\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.74505496234732e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.74505496234732e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253515948795656, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253515948795656\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.686861\tvalid_0's binary_error: 0.415\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.686012\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.683777\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.681982\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.678346\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.678521\tvalid_0's binary_error: 0.42\n",
      "[7]\tvalid_0's binary_logloss: 0.67992\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.681364\tvalid_0's binary_error: 0.44\n",
      "[9]\tvalid_0's binary_logloss: 0.689626\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.685058\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.686986\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.686861\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8721790148799835, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8721790148799835\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.008116806773293541, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.008116806773293541\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.74505496234732e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.74505496234732e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9253515948795656, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9253515948795656\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Accuracy-> 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:50,240] Trial 22 finished with value: 0.41000000000000003 and parameters: {'learning_rate': 0.02533325414598029, 'num_leaves': 90, 'max_depth': 8, 'min_data_in_leaf': 10, 'feature_fraction': 0.8129996131053508, 'bagging_fraction': 0.9970396907141885, 'bagging_freq': 10, 'lambda_l1': 0.041057306727717374, 'lambda_l2': 6.8809818771129545e-06}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:50,371] Trial 23 finished with value: 0.44999999999999996 and parameters: {'learning_rate': 0.029312344197382167, 'num_leaves': 91, 'max_depth': 9, 'min_data_in_leaf': 10, 'feature_fraction': 0.8187561964885658, 'bagging_fraction': 0.9771796417249, 'bagging_freq': 10, 'lambda_l1': 0.08884302024896827, 'lambda_l2': 6.4859281535359745e-06}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8129996131053508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8129996131053508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.041057306727717374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.041057306727717374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.8809818771129545e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.8809818771129545e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9970396907141885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9970396907141885\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8129996131053508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8129996131053508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.041057306727717374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.041057306727717374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.8809818771129545e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.8809818771129545e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9970396907141885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9970396907141885\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8129996131053508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8129996131053508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.041057306727717374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.041057306727717374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.8809818771129545e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.8809818771129545e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9970396907141885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9970396907141885\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690439\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690197\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.689473\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688563\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.687655\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687608\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.687246\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.686687\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.686628\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.68767\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.687718\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.68608\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685638\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.684345\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.683596\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.68231\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.682969\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.682316\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.683083\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.683244\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.682506\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.680788\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's binary_logloss: 0.680983\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's binary_logloss: 0.681051\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's binary_logloss: 0.680594\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's binary_logloss: 0.680975\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's binary_logloss: 0.68231\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8129996131053508, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8129996131053508\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.041057306727717374, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.041057306727717374\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.8809818771129545e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.8809818771129545e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9970396907141885, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9970396907141885\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.59\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8187561964885658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8187561964885658\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08884302024896827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08884302024896827\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.4859281535359745e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.4859281535359745e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9771796417249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9771796417249\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8187561964885658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8187561964885658\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08884302024896827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08884302024896827\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.4859281535359745e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.4859281535359745e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9771796417249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9771796417249\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8187561964885658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8187561964885658\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08884302024896827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08884302024896827\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.4859281535359745e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.4859281535359745e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9771796417249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9771796417249\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690095\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690525\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690109\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690814\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689585\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690952\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.69027\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.690335\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.689037\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.687998\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.687261\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.686709\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.686824\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.686872\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.687384\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.687732\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.6882\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.688402\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.68861\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.688588\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.687675\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.687039\tvalid_0's binary_error: 0.435\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_logloss: 0.686709\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8187561964885658, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8187561964885658\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08884302024896827, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08884302024896827\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.4859281535359745e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.4859281535359745e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9771796417249, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9771796417249\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:50,494] Trial 24 finished with value: 0.44499999999999995 and parameters: {'learning_rate': 0.04643417004145411, 'num_leaves': 91, 'max_depth': 7, 'min_data_in_leaf': 18, 'feature_fraction': 0.7442697532071304, 'bagging_fraction': 0.9498225794018526, 'bagging_freq': 8, 'lambda_l1': 0.8552278187557819, 'lambda_l2': 3.156572454686006e-07}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:50,627] Trial 25 finished with value: 0.5 and parameters: {'learning_rate': 0.1158852454811366, 'num_leaves': 100, 'max_depth': 10, 'min_data_in_leaf': 7, 'feature_fraction': 0.8306222701892367, 'bagging_fraction': 0.9913068950081837, 'bagging_freq': 10, 'lambda_l1': 0.9032731108495877, 'lambda_l2': 0.00019498881697101883}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442697532071304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442697532071304\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8552278187557819, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8552278187557819\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.156572454686006e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.156572454686006e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9498225794018526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9498225794018526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442697532071304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442697532071304\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8552278187557819, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8552278187557819\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.156572454686006e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.156572454686006e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9498225794018526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9498225794018526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442697532071304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442697532071304\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8552278187557819, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8552278187557819\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.156572454686006e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.156572454686006e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9498225794018526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9498225794018526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690594\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.68813\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.686778\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.686898\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.685475\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.685317\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.684324\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.68362\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.684095\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.684824\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.685285\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.685826\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.686353\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.685239\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.686643\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.687383\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.6879\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.688971\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.68362\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442697532071304, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442697532071304\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8552278187557819, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8552278187557819\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.156572454686006e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.156572454686006e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9498225794018526, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9498225794018526\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Accuracy-> 0.555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8306222701892367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8306222701892367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9032731108495877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9032731108495877\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00019498881697101883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00019498881697101883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913068950081837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913068950081837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8306222701892367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8306222701892367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9032731108495877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9032731108495877\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00019498881697101883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00019498881697101883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913068950081837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913068950081837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8306222701892367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8306222701892367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9032731108495877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9032731108495877\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00019498881697101883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00019498881697101883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913068950081837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913068950081837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.692207\tvalid_0's binary_error: 0.485\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.694345\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690843\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691964\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.690378\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.69403\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.68979\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.692422\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.692116\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.692781\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.69302\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.697469\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.695411\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.695884\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.698765\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.7033\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.70713\tvalid_0's binary_error: 0.485\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.68979\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8306222701892367, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8306222701892367\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9032731108495877, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9032731108495877\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00019498881697101883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00019498881697101883\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9913068950081837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9913068950081837\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:50,748] Trial 26 finished with value: 0.43000000000000005 and parameters: {'learning_rate': 0.06742463245577943, 'num_leaves': 69, 'max_depth': 8, 'min_data_in_leaf': 21, 'feature_fraction': 0.7632009188293642, 'bagging_fraction': 0.8823122553384346, 'bagging_freq': 9, 'lambda_l1': 0.023452327352461503, 'lambda_l2': 1.1045978454603972e-05}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:50,876] Trial 27 finished with value: 0.44499999999999995 and parameters: {'learning_rate': 0.02410287909323825, 'num_leaves': 65, 'max_depth': 5, 'min_data_in_leaf': 13, 'feature_fraction': 0.7233761989601661, 'bagging_fraction': 0.6971912244425013, 'bagging_freq': 7, 'lambda_l1': 0.0011652130092348683, 'lambda_l2': 7.150527121045647e-07}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7632009188293642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7632009188293642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.023452327352461503, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023452327352461503\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1045978454603972e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1045978454603972e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8823122553384346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823122553384346\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7632009188293642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7632009188293642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.023452327352461503, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023452327352461503\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1045978454603972e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1045978454603972e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8823122553384346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823122553384346\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7632009188293642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7632009188293642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.023452327352461503, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023452327352461503\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1045978454603972e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1045978454603972e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8823122553384346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823122553384346\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691263\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691227\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687018\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690511\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.686729\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.68498\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.686654\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.687055\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.68668\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.687305\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.686881\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.686542\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685279\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.687018\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7632009188293642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7632009188293642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.023452327352461503, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023452327352461503\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1045978454603972e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1045978454603972e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8823122553384346, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8823122553384346\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.57\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7233761989601661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7233761989601661\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0011652130092348683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011652130092348683\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.150527121045647e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.150527121045647e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6971912244425013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6971912244425013\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7233761989601661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7233761989601661\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0011652130092348683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011652130092348683\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.150527121045647e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.150527121045647e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6971912244425013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6971912244425013\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7233761989601661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7233761989601661\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0011652130092348683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011652130092348683\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.150527121045647e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.150527121045647e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6971912244425013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6971912244425013\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691565\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.69087\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690736\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.691778\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691913\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691845\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691748\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.691106\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.689746\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.68881\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.688251\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.687053\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.686259\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.68578\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.686245\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.685853\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.685495\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.685645\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.685089\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.684982\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.684615\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.68448\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's binary_logloss: 0.684539\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's binary_logloss: 0.685188\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's binary_logloss: 0.685746\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's binary_logloss: 0.686719\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's binary_logloss: 0.686189\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's binary_logloss: 0.686214\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's binary_logloss: 0.686679\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.687341\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's binary_logloss: 0.686407\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's binary_logloss: 0.686938\tvalid_0's binary_error: 0.41\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's binary_logloss: 0.68448\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7233761989601661, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7233761989601661\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0011652130092348683, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0011652130092348683\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.150527121045647e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.150527121045647e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6971912244425013, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6971912244425013\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Accuracy-> 0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:50,989] Trial 28 finished with value: 0.475 and parameters: {'learning_rate': 0.045172695630425655, 'num_leaves': 88, 'max_depth': 9, 'min_data_in_leaf': 7, 'feature_fraction': 0.5040182250254119, 'bagging_fraction': 0.8153597477719726, 'bagging_freq': 10, 'lambda_l1': 1.4416727115834945e-07, 'lambda_l2': 7.027310880634685e-05}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:51,107] Trial 29 finished with value: 0.48 and parameters: {'learning_rate': 0.09599070440415763, 'num_leaves': 73, 'max_depth': 4, 'min_data_in_leaf': 28, 'feature_fraction': 0.683361863383231, 'bagging_fraction': 0.9046501841401957, 'bagging_freq': 9, 'lambda_l1': 0.00010955642682635552, 'lambda_l2': 0.006467424715728729}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040182250254119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040182250254119\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4416727115834945e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4416727115834945e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.027310880634685e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.027310880634685e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8153597477719726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8153597477719726\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040182250254119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040182250254119\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4416727115834945e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4416727115834945e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.027310880634685e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.027310880634685e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8153597477719726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8153597477719726\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040182250254119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040182250254119\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4416727115834945e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4416727115834945e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.027310880634685e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.027310880634685e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8153597477719726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8153597477719726\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689872\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689771\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687981\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688313\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.68968\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691632\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.691308\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689978\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.690405\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.68856\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.689785\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.691332\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.691159\tvalid_0's binary_error: 0.445\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.687981\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040182250254119, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040182250254119\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4416727115834945e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4416727115834945e-07\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.027310880634685e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.027310880634685e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8153597477719726, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8153597477719726\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.683361863383231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.683361863383231\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010955642682635552, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010955642682635552\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.006467424715728729, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006467424715728729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9046501841401957, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9046501841401957\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.683361863383231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.683361863383231\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010955642682635552, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010955642682635552\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.006467424715728729, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006467424715728729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9046501841401957, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9046501841401957\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.683361863383231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.683361863383231\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010955642682635552, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010955642682635552\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.006467424715728729, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006467424715728729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9046501841401957, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9046501841401957\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.692275\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.692518\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.693197\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.69187\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689754\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690736\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690743\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.692509\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.6922\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.691721\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.691877\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.692567\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.692439\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.693018\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.695498\tvalid_0's binary_error: 0.46\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's binary_logloss: 0.689754\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.683361863383231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.683361863383231\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00010955642682635552, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00010955642682635552\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.006467424715728729, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.006467424715728729\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9046501841401957, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9046501841401957\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:51,238] Trial 30 finished with value: 0.43000000000000005 and parameters: {'learning_rate': 0.010694280850274683, 'num_leaves': 76, 'max_depth': 7, 'min_data_in_leaf': 16, 'feature_fraction': 0.8972189139650841, 'bagging_fraction': 0.9994886291257211, 'bagging_freq': 8, 'lambda_l1': 0.02073229208290262, 'lambda_l2': 0.5414044616636133}. Best is trial 14 with value: 0.405.\n",
      "[I 2025-04-06 16:37:51,365] Trial 31 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.01885792975840952, 'num_leaves': 83, 'max_depth': 8, 'min_data_in_leaf': 1, 'feature_fraction': 0.8864946721020187, 'bagging_fraction': 0.9293643507688879, 'bagging_freq': 5, 'lambda_l1': 0.002266619382103973, 'lambda_l2': 8.14028423823976e-08}. Best is trial 14 with value: 0.405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8972189139650841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8972189139650841\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02073229208290262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02073229208290262\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5414044616636133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5414044616636133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994886291257211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994886291257211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8972189139650841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8972189139650841\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02073229208290262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02073229208290262\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5414044616636133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5414044616636133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994886291257211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994886291257211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8972189139650841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8972189139650841\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02073229208290262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02073229208290262\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5414044616636133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5414044616636133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994886291257211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994886291257211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691311\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691173\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691065\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690359\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.690061\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.689405\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.689332\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689304\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.689208\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689195\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.689004\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.688823\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.688752\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.68852\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.68815\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.687937\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.687698\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.687496\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.687336\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.686983\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.686949\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.686951\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's binary_logloss: 0.686753\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's binary_logloss: 0.686529\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's binary_logloss: 0.686375\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's binary_logloss: 0.686342\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's binary_logloss: 0.686231\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's binary_logloss: 0.686139\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's binary_logloss: 0.686059\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's binary_logloss: 0.686147\tvalid_0's binary_error: 0.445\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's binary_logloss: 0.686983\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=16, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=16\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8972189139650841, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8972189139650841\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02073229208290262, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02073229208290262\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5414044616636133, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5414044616636133\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9994886291257211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9994886291257211\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Accuracy-> 0.57\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8864946721020187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8864946721020187\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002266619382103973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002266619382103973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.14028423823976e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.14028423823976e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9293643507688879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9293643507688879\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8864946721020187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8864946721020187\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002266619382103973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002266619382103973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.14028423823976e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.14028423823976e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9293643507688879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9293643507688879\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8864946721020187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8864946721020187\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002266619382103973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002266619382103973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.14028423823976e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.14028423823976e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9293643507688879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9293643507688879\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689699\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689202\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687929\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.686997\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.686916\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.686688\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.686148\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.686967\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.686574\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.685621\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.686041\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.685586\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685036\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.687929\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8864946721020187, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8864946721020187\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002266619382103973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002266619382103973\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.14028423823976e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.14028423823976e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9293643507688879, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9293643507688879\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:51,527] Trial 32 finished with value: 0.385 and parameters: {'learning_rate': 0.017622496023118293, 'num_leaves': 95, 'max_depth': 8, 'min_data_in_leaf': 5, 'feature_fraction': 0.834703517299954, 'bagging_fraction': 0.9466501690077729, 'bagging_freq': 3, 'lambda_l1': 0.02335186096436572, 'lambda_l2': 5.293104531028167e-06}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:51,647] Trial 33 finished with value: 0.47 and parameters: {'learning_rate': 0.013312489115335616, 'num_leaves': 96, 'max_depth': 6, 'min_data_in_leaf': 25, 'feature_fraction': 0.8359570378275962, 'bagging_fraction': 0.9511466055481779, 'bagging_freq': 3, 'lambda_l1': 0.2981753511552631, 'lambda_l2': 6.2432726563114785e-06}. Best is trial 32 with value: 0.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.834703517299954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.834703517299954\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02335186096436572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02335186096436572\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.293104531028167e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.293104531028167e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9466501690077729, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9466501690077729\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.834703517299954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.834703517299954\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02335186096436572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02335186096436572\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.293104531028167e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.293104531028167e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9466501690077729, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9466501690077729\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.834703517299954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.834703517299954\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02335186096436572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02335186096436572\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.293104531028167e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.293104531028167e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9466501690077729, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9466501690077729\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689894\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.688693\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687377\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.686556\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.684919\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.684032\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.682965\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.682516\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.68228\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.682346\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.681915\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.681596\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.680595\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.680238\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.679461\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.679157\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.679518\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.678527\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.679391\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.678704\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.678337\tvalid_0's binary_error: 0.39\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's binary_logloss: 0.681915\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.834703517299954, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.834703517299954\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02335186096436572, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02335186096436572\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.293104531028167e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.293104531028167e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9466501690077729, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9466501690077729\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.615\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8359570378275962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8359570378275962\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2981753511552631, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2981753511552631\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2432726563114785e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2432726563114785e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9511466055481779, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9511466055481779\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8359570378275962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8359570378275962\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2981753511552631, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2981753511552631\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2432726563114785e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2432726563114785e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9511466055481779, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9511466055481779\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8359570378275962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8359570378275962\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2981753511552631, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2981753511552631\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2432726563114785e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2432726563114785e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9511466055481779, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9511466055481779\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690866\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690529\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690196\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690302\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.69039\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690258\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690148\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.690101\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.69026\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.690263\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.690344\tvalid_0's binary_error: 0.485\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.690866\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=25, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8359570378275962, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8359570378275962\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2981753511552631, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2981753511552631\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.2432726563114785e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.2432726563114785e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9511466055481779, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9511466055481779\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:51,791] Trial 34 finished with value: 0.43500000000000005 and parameters: {'learning_rate': 0.02995842568960134, 'num_leaves': 92, 'max_depth': 8, 'min_data_in_leaf': 5, 'feature_fraction': 0.787174038846388, 'bagging_fraction': 0.9446312850467695, 'bagging_freq': 1, 'lambda_l1': 0.021423226882774118, 'lambda_l2': 0.0004761941508614209}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:51,922] Trial 35 finished with value: 0.41000000000000003 and parameters: {'learning_rate': 0.01877675931512406, 'num_leaves': 81, 'max_depth': 7, 'min_data_in_leaf': 9, 'feature_fraction': 0.8465173492770993, 'bagging_fraction': 0.8686796898901499, 'bagging_freq': 3, 'lambda_l1': 2.7161385882438328e-06, 'lambda_l2': 1.4151191356828096e-06}. Best is trial 32 with value: 0.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787174038846388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787174038846388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.021423226882774118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021423226882774118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0004761941508614209, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004761941508614209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9446312850467695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9446312850467695\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787174038846388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787174038846388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.021423226882774118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021423226882774118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0004761941508614209, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004761941508614209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9446312850467695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9446312850467695\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787174038846388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787174038846388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.021423226882774118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021423226882774118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0004761941508614209, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004761941508614209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9446312850467695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9446312850467695\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.69043\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691655\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.689933\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688108\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.688112\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687513\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.687495\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.687715\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.688434\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.687634\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.687119\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.686942\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685649\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.684918\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.684389\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.685046\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's binary_logloss: 0.684836\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's binary_logloss: 0.683893\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's binary_logloss: 0.683937\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's binary_logloss: 0.68441\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's binary_logloss: 0.683729\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's binary_logloss: 0.682241\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's binary_logloss: 0.682845\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_logloss: 0.685649\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.787174038846388, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.787174038846388\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.021423226882774118, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021423226882774118\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0004761941508614209, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004761941508614209\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9446312850467695, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9446312850467695\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.565\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465173492770993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465173492770993\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7161385882438328e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7161385882438328e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4151191356828096e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4151191356828096e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8686796898901499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8686796898901499\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465173492770993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465173492770993\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7161385882438328e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7161385882438328e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4151191356828096e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4151191356828096e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8686796898901499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8686796898901499\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465173492770993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465173492770993\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7161385882438328e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7161385882438328e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4151191356828096e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4151191356828096e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8686796898901499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8686796898901499\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690821\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689699\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.688468\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688087\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.68785\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687111\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.687054\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.687019\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.686632\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.685755\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.685808\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.685953\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.685454\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.685504\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.685379\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.685254\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.687111\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8465173492770993, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8465173492770993\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.7161385882438328e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.7161385882438328e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4151191356828096e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4151191356828096e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8686796898901499, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8686796898901499\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:52,045] Trial 36 finished with value: 0.44499999999999995 and parameters: {'learning_rate': 0.059689203886849784, 'num_leaves': 87, 'max_depth': 9, 'min_data_in_leaf': 13, 'feature_fraction': 0.8091117427550778, 'bagging_fraction': 0.9093516786196117, 'bagging_freq': 4, 'lambda_l1': 6.538664966433233e-05, 'lambda_l2': 4.557065760671245e-06}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:52,165] Trial 37 finished with value: 0.47 and parameters: {'learning_rate': 0.01233724916462015, 'num_leaves': 96, 'max_depth': 8, 'min_data_in_leaf': 20, 'feature_fraction': 0.9032649656788034, 'bagging_fraction': 0.9675349905379306, 'bagging_freq': 10, 'lambda_l1': 3.006535915756935, 'lambda_l2': 3.548460838127889e-05}. Best is trial 32 with value: 0.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8091117427550778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091117427550778\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.538664966433233e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.538664966433233e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.557065760671245e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.557065760671245e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093516786196117, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9093516786196117\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8091117427550778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091117427550778\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.538664966433233e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.538664966433233e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.557065760671245e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.557065760671245e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093516786196117, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9093516786196117\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8091117427550778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091117427550778\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.538664966433233e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.538664966433233e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.557065760671245e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.557065760671245e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093516786196117, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9093516786196117\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.692163\tvalid_0's binary_error: 0.48\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691249\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687196\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689247\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689309\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690225\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.687805\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689151\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.690127\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689113\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.690697\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.691913\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.692896\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.687196\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8091117427550778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091117427550778\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.538664966433233e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.538664966433233e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.557065760671245e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.557065760671245e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9093516786196117, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9093516786196117\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9032649656788034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9032649656788034\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.006535915756935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.006535915756935\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.548460838127889e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.548460838127889e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9675349905379306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9675349905379306\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9032649656788034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9032649656788034\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.006535915756935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.006535915756935\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.548460838127889e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.548460838127889e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9675349905379306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9675349905379306\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9032649656788034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9032649656788034\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.006535915756935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.006535915756935\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.548460838127889e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.548460838127889e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9675349905379306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9675349905379306\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.691122\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690844\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.690596\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.690255\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.690034\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.689722\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.689443\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689174\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.689416\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689177\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.689271\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.691122\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9032649656788034, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9032649656788034\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.006535915756935, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.006535915756935\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.548460838127889e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.548460838127889e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9675349905379306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9675349905379306\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Accuracy-> 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:52,285] Trial 38 finished with value: 0.47 and parameters: {'learning_rate': 0.020943999093615055, 'num_leaves': 50, 'max_depth': 10, 'min_data_in_leaf': 15, 'feature_fraction': 0.7458248695080917, 'bagging_fraction': 0.7151185822843269, 'bagging_freq': 9, 'lambda_l1': 0.2332209175724658, 'lambda_l2': 5.211503568557974e-07}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:52,399] Trial 39 finished with value: 0.4 and parameters: {'learning_rate': 0.15499067882123657, 'num_leaves': 74, 'max_depth': 7, 'min_data_in_leaf': 4, 'feature_fraction': 0.9304231072742094, 'bagging_fraction': 0.9742984855003697, 'bagging_freq': 2, 'lambda_l1': 0.015143807848028545, 'lambda_l2': 1.7404890470374416e-07}. Best is trial 32 with value: 0.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7458248695080917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458248695080917\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2332209175724658, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2332209175724658\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.211503568557974e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.211503568557974e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7151185822843269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7151185822843269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7458248695080917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458248695080917\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2332209175724658, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2332209175724658\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.211503568557974e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.211503568557974e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7151185822843269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7151185822843269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7458248695080917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458248695080917\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2332209175724658, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2332209175724658\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.211503568557974e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.211503568557974e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7151185822843269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7151185822843269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690407\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689464\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.689027\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689506\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689589\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690326\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690396\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.689851\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.690262\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.690523\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.690306\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.689593\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.68904\tvalid_0's binary_error: 0.44\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.689027\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7458248695080917, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7458248695080917\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2332209175724658, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2332209175724658\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.211503568557974e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.211503568557974e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7151185822843269, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7151185822843269\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Accuracy-> 0.53\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9304231072742094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9304231072742094\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015143807848028545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015143807848028545\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7404890470374416e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7404890470374416e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9742984855003697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9742984855003697\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9304231072742094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9304231072742094\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015143807848028545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015143807848028545\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7404890470374416e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7404890470374416e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9742984855003697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9742984855003697\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9304231072742094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9304231072742094\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015143807848028545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015143807848028545\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7404890470374416e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7404890470374416e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9742984855003697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9742984855003697\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.683883\tvalid_0's binary_error: 0.41\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.677194\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687443\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.693585\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.696246\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.713279\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.706716\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.707285\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.707963\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.70731\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.704426\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.708337\tvalid_0's binary_error: 0.48\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.677194\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9304231072742094, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9304231072742094\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.015143807848028545, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015143807848028545\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.7404890470374416e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7404890470374416e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9742984855003697, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9742984855003697\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:52,516] Trial 40 finished with value: 0.515 and parameters: {'learning_rate': 0.17293485045917575, 'num_leaves': 76, 'max_depth': 6, 'min_data_in_leaf': 28, 'feature_fraction': 0.9679939138271191, 'bagging_fraction': 0.8466686549410838, 'bagging_freq': 1, 'lambda_l1': 0.011453134715059017, 'lambda_l2': 1.253923503364511e-07}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:52,640] Trial 41 finished with value: 0.45499999999999996 and parameters: {'learning_rate': 0.15421079595694273, 'num_leaves': 89, 'max_depth': 7, 'min_data_in_leaf': 8, 'feature_fraction': 0.9255071744621413, 'bagging_fraction': 0.9702761965433325, 'bagging_freq': 2, 'lambda_l1': 0.04311912307425553, 'lambda_l2': 1.1180801725638885e-06}. Best is trial 32 with value: 0.385.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9679939138271191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9679939138271191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.011453134715059017, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011453134715059017\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.253923503364511e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.253923503364511e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8466686549410838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8466686549410838\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9679939138271191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9679939138271191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.011453134715059017, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011453134715059017\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.253923503364511e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.253923503364511e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8466686549410838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8466686549410838\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9679939138271191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9679939138271191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.011453134715059017, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011453134715059017\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.253923503364511e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.253923503364511e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8466686549410838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8466686549410838\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.694344\tvalid_0's binary_error: 0.515\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.696901\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.700781\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.700487\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.699831\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.698712\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.704133\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.703306\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.704378\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.701837\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.708534\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.694344\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9679939138271191, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9679939138271191\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.011453134715059017, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011453134715059017\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.253923503364511e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.253923503364511e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8466686549410838, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8466686549410838\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.485\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9255071744621413, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9255071744621413\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04311912307425553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04311912307425553\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1180801725638885e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1180801725638885e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702761965433325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702761965433325\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9255071744621413, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9255071744621413\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04311912307425553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04311912307425553\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1180801725638885e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1180801725638885e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702761965433325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702761965433325\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9255071744621413, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9255071744621413\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04311912307425553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04311912307425553\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1180801725638885e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1180801725638885e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702761965433325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702761965433325\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.686613\tvalid_0's binary_error: 0.455\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.68366\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.684237\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.68438\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689168\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.688068\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.686535\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.684281\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691387\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696756\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.709861\tvalid_0's binary_error: 0.525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.71028\tvalid_0's binary_error: 0.545\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.68366\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9255071744621413, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9255071744621413\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04311912307425553, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04311912307425553\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1180801725638885e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1180801725638885e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9702761965433325, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9702761965433325\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:52,764] Trial 42 finished with value: 0.395 and parameters: {'learning_rate': 0.2135837564459426, 'num_leaves': 72, 'max_depth': 8, 'min_data_in_leaf': 5, 'feature_fraction': 0.8577235898756062, 'bagging_fraction': 0.9403045808945507, 'bagging_freq': 2, 'lambda_l1': 0.002761597611568825, 'lambda_l2': 2.5771041025628443e-07}. Best is trial 32 with value: 0.385.\n",
      "[I 2025-04-06 16:37:52,893] Trial 43 finished with value: 0.36 and parameters: {'learning_rate': 0.23106117383955713, 'num_leaves': 62, 'max_depth': 7, 'min_data_in_leaf': 4, 'feature_fraction': 0.9408951396418745, 'bagging_fraction': 0.9022683329874014, 'bagging_freq': 2, 'lambda_l1': 0.00217889325401306, 'lambda_l2': 2.6603791433841303e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8577235898756062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8577235898756062\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002761597611568825, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002761597611568825\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5771041025628443e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5771041025628443e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9403045808945507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9403045808945507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8577235898756062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8577235898756062\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002761597611568825, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002761597611568825\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5771041025628443e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5771041025628443e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9403045808945507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9403045808945507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8577235898756062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8577235898756062\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002761597611568825, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002761597611568825\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5771041025628443e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5771041025628443e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9403045808945507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9403045808945507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.679692\tvalid_0's binary_error: 0.395\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.686024\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.693867\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.696203\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.705573\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.708922\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.694104\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.687819\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.694683\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.689553\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.686435\tvalid_0's binary_error: 0.435\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.679692\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8577235898756062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8577235898756062\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002761597611568825, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002761597611568825\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.5771041025628443e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.5771041025628443e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9403045808945507, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9403045808945507\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9408951396418745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9408951396418745\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00217889325401306, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00217889325401306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6603791433841303e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6603791433841303e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9022683329874014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9022683329874014\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9408951396418745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9408951396418745\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00217889325401306, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00217889325401306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6603791433841303e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6603791433841303e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9022683329874014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9022683329874014\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9408951396418745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9408951396418745\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00217889325401306, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00217889325401306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6603791433841303e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6603791433841303e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9022683329874014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9022683329874014\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.675046\tvalid_0's binary_error: 0.395\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.671419\tvalid_0's binary_error: 0.36\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.673403\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.678843\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.687191\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.690381\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690583\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.695254\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.709851\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.715803\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.7185\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.720192\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.671419\tvalid_0's binary_error: 0.36\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9408951396418745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9408951396418745\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00217889325401306, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00217889325401306\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.6603791433841303e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.6603791433841303e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9022683329874014, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9022683329874014\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:53,032] Trial 44 finished with value: 0.39 and parameters: {'learning_rate': 0.2938292995945352, 'num_leaves': 62, 'max_depth': 7, 'min_data_in_leaf': 3, 'feature_fraction': 0.9530085062341893, 'bagging_fraction': 0.9379639692098601, 'bagging_freq': 2, 'lambda_l1': 0.0016544705897020896, 'lambda_l2': 2.042181638358442e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:53,153] Trial 45 finished with value: 0.43000000000000005 and parameters: {'learning_rate': 0.2683751162564681, 'num_leaves': 60, 'max_depth': 7, 'min_data_in_leaf': 4, 'feature_fraction': 0.9456091958312888, 'bagging_fraction': 0.9162035773958814, 'bagging_freq': 2, 'lambda_l1': 0.0013167890108051145, 'lambda_l2': 3.149204574216833e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530085062341893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530085062341893\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016544705897020896, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0016544705897020896\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.042181638358442e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.042181638358442e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9379639692098601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9379639692098601\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530085062341893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530085062341893\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016544705897020896, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0016544705897020896\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.042181638358442e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.042181638358442e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9379639692098601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9379639692098601\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530085062341893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530085062341893\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016544705897020896, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0016544705897020896\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.042181638358442e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.042181638358442e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9379639692098601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9379639692098601\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.680205\tvalid_0's binary_error: 0.44\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.673087\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.670533\tvalid_0's binary_error: 0.39\n",
      "[4]\tvalid_0's binary_logloss: 0.699606\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.706898\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.721912\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.72149\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.728522\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.734819\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.736523\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.740552\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.745339\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.751396\tvalid_0's binary_error: 0.445\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.670533\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9530085062341893, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9530085062341893\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0016544705897020896, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0016544705897020896\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.042181638358442e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.042181638358442e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9379639692098601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9379639692098601\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.61\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9456091958312888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9456091958312888\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0013167890108051145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013167890108051145\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.149204574216833e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.149204574216833e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9162035773958814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9162035773958814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9456091958312888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9456091958312888\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0013167890108051145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013167890108051145\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.149204574216833e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.149204574216833e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9162035773958814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9162035773958814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9456091958312888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9456091958312888\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0013167890108051145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013167890108051145\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.149204574216833e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.149204574216833e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9162035773958814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9162035773958814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.675549\tvalid_0's binary_error: 0.43\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.682896\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.677915\tvalid_0's binary_error: 0.42\n",
      "[4]\tvalid_0's binary_logloss: 0.699269\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.69304\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.700597\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.697484\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.719116\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.721965\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.728587\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.732421\tvalid_0's binary_error: 0.42\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.675549\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9456091958312888, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9456091958312888\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0013167890108051145, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0013167890108051145\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.149204574216833e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.149204574216833e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9162035773958814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9162035773958814\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:53,279] Trial 46 finished with value: 0.405 and parameters: {'learning_rate': 0.2199839540076995, 'num_leaves': 54, 'max_depth': 6, 'min_data_in_leaf': 1, 'feature_fraction': 0.9994178181050244, 'bagging_fraction': 0.9396392048709481, 'bagging_freq': 2, 'lambda_l1': 0.00021847090814777534, 'lambda_l2': 1.904249284569368e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:53,387] Trial 47 finished with value: 0.515 and parameters: {'learning_rate': 0.21301096196832842, 'num_leaves': 40, 'max_depth': 7, 'min_data_in_leaf': 4, 'feature_fraction': 0.9220073717040997, 'bagging_fraction': 0.8038646020617317, 'bagging_freq': 3, 'lambda_l1': 0.0028600751928042636, 'lambda_l2': 2.7757548708036532e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9994178181050244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9994178181050244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00021847090814777534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021847090814777534\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.904249284569368e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.904249284569368e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9396392048709481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9396392048709481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9994178181050244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9994178181050244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00021847090814777534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021847090814777534\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.904249284569368e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.904249284569368e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9396392048709481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9396392048709481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9994178181050244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9994178181050244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00021847090814777534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021847090814777534\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.904249284569368e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.904249284569368e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9396392048709481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9396392048709481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.677497\tvalid_0's binary_error: 0.41\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.677134\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.682806\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.682816\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.674566\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.681576\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.679744\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.68864\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.690191\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696032\tvalid_0's binary_error: 0.47\n",
      "[11]\tvalid_0's binary_logloss: 0.712445\tvalid_0's binary_error: 0.475\n",
      "[12]\tvalid_0's binary_logloss: 0.707067\tvalid_0's binary_error: 0.48\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.677134\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9994178181050244, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9994178181050244\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00021847090814777534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021847090814777534\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.904249284569368e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.904249284569368e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9396392048709481, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9396392048709481\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.595\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9220073717040997, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9220073717040997\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0028600751928042636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0028600751928042636\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7757548708036532e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7757548708036532e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8038646020617317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8038646020617317\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9220073717040997, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9220073717040997\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0028600751928042636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0028600751928042636\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7757548708036532e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7757548708036532e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8038646020617317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8038646020617317\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9220073717040997, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9220073717040997\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0028600751928042636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0028600751928042636\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7757548708036532e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7757548708036532e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8038646020617317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8038646020617317\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[1]\tvalid_0's binary_logloss: 0.700458\tvalid_0's binary_error: 0.515\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.701246\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.715042\tvalid_0's binary_error: 0.505\n",
      "[4]\tvalid_0's binary_logloss: 0.711414\tvalid_0's binary_error: 0.515\n",
      "[5]\tvalid_0's binary_logloss: 0.713696\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.730538\tvalid_0's binary_error: 0.495\n",
      "[7]\tvalid_0's binary_logloss: 0.737086\tvalid_0's binary_error: 0.505\n",
      "[8]\tvalid_0's binary_logloss: 0.73765\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.741505\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.74202\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.751106\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.700458\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9220073717040997, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9220073717040997\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0028600751928042636, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0028600751928042636\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.7757548708036532e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.7757548708036532e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8038646020617317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8038646020617317\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:53,513] Trial 48 finished with value: 0.505 and parameters: {'learning_rate': 0.2517624283102008, 'num_leaves': 64, 'max_depth': 8, 'min_data_in_leaf': 5, 'feature_fraction': 0.9684177482349885, 'bagging_fraction': 0.7605256858068624, 'bagging_freq': 3, 'lambda_l1': 0.00047743297428179204, 'lambda_l2': 2.265086063002616e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:53,632] Trial 49 finished with value: 0.49 and parameters: {'learning_rate': 0.18499902809540517, 'num_leaves': 69, 'max_depth': 7, 'min_data_in_leaf': 3, 'feature_fraction': 0.9064140490125147, 'bagging_fraction': 0.8383301657710298, 'bagging_freq': 1, 'lambda_l1': 0.005961133294420065, 'lambda_l2': 6.6317998956468e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9684177482349885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684177482349885\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00047743297428179204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00047743297428179204\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.265086063002616e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.265086063002616e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7605256858068624, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7605256858068624\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9684177482349885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684177482349885\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00047743297428179204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00047743297428179204\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.265086063002616e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.265086063002616e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7605256858068624, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7605256858068624\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9684177482349885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684177482349885\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00047743297428179204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00047743297428179204\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.265086063002616e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.265086063002616e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7605256858068624, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7605256858068624\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.704846\tvalid_0's binary_error: 0.505\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.718214\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.725245\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.743417\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.750202\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.756125\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.74488\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.758845\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.774727\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.78033\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.775502\tvalid_0's binary_error: 0.495\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.704846\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9684177482349885, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9684177482349885\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00047743297428179204, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00047743297428179204\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.265086063002616e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.265086063002616e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7605256858068624, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7605256858068624\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.495\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064140490125147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064140490125147\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005961133294420065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005961133294420065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.6317998956468e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.6317998956468e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8383301657710298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8383301657710298\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064140490125147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064140490125147\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005961133294420065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005961133294420065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.6317998956468e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.6317998956468e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8383301657710298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8383301657710298\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064140490125147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064140490125147\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005961133294420065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005961133294420065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.6317998956468e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.6317998956468e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8383301657710298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8383301657710298\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.696731\tvalid_0's binary_error: 0.49\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.700124\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.703262\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.702145\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.706165\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.716095\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.714011\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.720986\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.725031\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.719877\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.725699\tvalid_0's binary_error: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.696731\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9064140490125147, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9064140490125147\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.005961133294420065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005961133294420065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.6317998956468e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.6317998956468e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8383301657710298, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8383301657710298\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:53,757] Trial 50 finished with value: 0.405 and parameters: {'learning_rate': 0.14698639003045236, 'num_leaves': 56, 'max_depth': 8, 'min_data_in_leaf': 6, 'feature_fraction': 0.9501350622835711, 'bagging_fraction': 0.8725505599660188, 'bagging_freq': 2, 'lambda_l1': 0.0002117714853807384, 'lambda_l2': 1.031404339443111e-08}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:53,879] Trial 51 finished with value: 0.43000000000000005 and parameters: {'learning_rate': 0.29674245144151157, 'num_leaves': 63, 'max_depth': 7, 'min_data_in_leaf': 1, 'feature_fraction': 0.8705484223607131, 'bagging_fraction': 0.9563702662040972, 'bagging_freq': 2, 'lambda_l1': 0.0020473245367473086, 'lambda_l2': 3.586848567760775e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9501350622835711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9501350622835711\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0002117714853807384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002117714853807384\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.031404339443111e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.031404339443111e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725505599660188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725505599660188\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9501350622835711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9501350622835711\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0002117714853807384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002117714853807384\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.031404339443111e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.031404339443111e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725505599660188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725505599660188\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9501350622835711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9501350622835711\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0002117714853807384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002117714853807384\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.031404339443111e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.031404339443111e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725505599660188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725505599660188\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.679794\tvalid_0's binary_error: 0.395\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.67817\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.680039\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.685653\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.686104\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.685585\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.684869\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.690309\tvalid_0's binary_error: 0.395\n",
      "[9]\tvalid_0's binary_logloss: 0.697114\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.703096\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.704615\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.706839\tvalid_0's binary_error: 0.445\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.67817\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9501350622835711, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9501350622835711\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0002117714853807384, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002117714853807384\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.031404339443111e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.031404339443111e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8725505599660188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8725505599660188\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.595\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8705484223607131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8705484223607131\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0020473245367473086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020473245367473086\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.586848567760775e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.586848567760775e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9563702662040972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9563702662040972\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8705484223607131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8705484223607131\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0020473245367473086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020473245367473086\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.586848567760775e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.586848567760775e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9563702662040972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9563702662040972\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8705484223607131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8705484223607131\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0020473245367473086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020473245367473086\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.586848567760775e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.586848567760775e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9563702662040972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9563702662040972\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.682534\tvalid_0's binary_error: 0.43\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.69161\tvalid_0's binary_error: 0.475\n",
      "[3]\tvalid_0's binary_logloss: 0.696811\tvalid_0's binary_error: 0.445\n",
      "[4]\tvalid_0's binary_logloss: 0.716171\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.72315\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.720989\tvalid_0's binary_error: 0.43\n",
      "[7]\tvalid_0's binary_logloss: 0.734617\tvalid_0's binary_error: 0.44\n",
      "[8]\tvalid_0's binary_logloss: 0.756041\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.773167\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.776053\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.783207\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.682534\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8705484223607131, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8705484223607131\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0020473245367473086, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020473245367473086\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.586848567760775e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.586848567760775e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9563702662040972, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9563702662040972\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:54,001] Trial 52 finished with value: 0.385 and parameters: {'learning_rate': 0.22824757105026863, 'num_leaves': 71, 'max_depth': 6, 'min_data_in_leaf': 8, 'feature_fraction': 0.9366160181476724, 'bagging_fraction': 0.978252604811952, 'bagging_freq': 4, 'lambda_l1': 0.0008093749096082989, 'lambda_l2': 1.2258855486560307e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:54,125] Trial 53 finished with value: 0.39 and parameters: {'learning_rate': 0.24656749338470374, 'num_leaves': 73, 'max_depth': 6, 'min_data_in_leaf': 8, 'feature_fraction': 0.9394510825274502, 'bagging_fraction': 0.9019829633311678, 'bagging_freq': 4, 'lambda_l1': 0.0008760964633972395, 'lambda_l2': 3.971275056314917e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9366160181476724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9366160181476724\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008093749096082989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008093749096082989\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2258855486560307e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2258855486560307e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.978252604811952, subsample=1.0 will be ignored. Current value: bagging_fraction=0.978252604811952\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9366160181476724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9366160181476724\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008093749096082989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008093749096082989\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2258855486560307e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2258855486560307e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.978252604811952, subsample=1.0 will be ignored. Current value: bagging_fraction=0.978252604811952\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9366160181476724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9366160181476724\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008093749096082989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008093749096082989\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2258855486560307e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2258855486560307e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.978252604811952, subsample=1.0 will be ignored. Current value: bagging_fraction=0.978252604811952\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.681605\tvalid_0's binary_error: 0.4\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.678866\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.685406\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.693716\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.695188\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.701307\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.702877\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.707798\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.707812\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.713865\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.716663\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.727632\tvalid_0's binary_error: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.678866\tvalid_0's binary_error: 0.385\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9366160181476724, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9366160181476724\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008093749096082989, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008093749096082989\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.2258855486560307e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2258855486560307e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.978252604811952, subsample=1.0 will be ignored. Current value: bagging_fraction=0.978252604811952\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.615\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9394510825274502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9394510825274502\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008760964633972395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008760964633972395\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.971275056314917e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.971275056314917e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9019829633311678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9019829633311678\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9394510825274502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9394510825274502\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008760964633972395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008760964633972395\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.971275056314917e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.971275056314917e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9019829633311678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9019829633311678\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9394510825274502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9394510825274502\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008760964633972395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008760964633972395\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.971275056314917e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.971275056314917e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9019829633311678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9019829633311678\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.686421\tvalid_0's binary_error: 0.44\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.687684\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.680414\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.672378\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.678379\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.697164\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.702912\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.715645\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.730024\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.737083\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.744259\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.740239\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.739279\tvalid_0's binary_error: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.680414\tvalid_0's binary_error: 0.39\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9394510825274502, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9394510825274502\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008760964633972395, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008760964633972395\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.971275056314917e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.971275056314917e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9019829633311678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9019829633311678\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:54,255] Trial 54 finished with value: 0.48 and parameters: {'learning_rate': 0.24575034612319532, 'num_leaves': 70, 'max_depth': 5, 'min_data_in_leaf': 8, 'feature_fraction': 0.9698091293295021, 'bagging_fraction': 0.9136668341153746, 'bagging_freq': 4, 'lambda_l1': 2.5518479738751866e-05, 'lambda_l2': 2.8733329158020348e-08}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:54,380] Trial 55 finished with value: 0.44999999999999996 and parameters: {'learning_rate': 0.1974518035144212, 'num_leaves': 57, 'max_depth': 6, 'min_data_in_leaf': 13, 'feature_fraction': 0.9911414324673796, 'bagging_fraction': 0.8940038518713825, 'bagging_freq': 4, 'lambda_l1': 0.0007531463018402133, 'lambda_l2': 5.488337032772606e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9698091293295021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9698091293295021\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5518479738751866e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5518479738751866e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8733329158020348e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8733329158020348e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9136668341153746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136668341153746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9698091293295021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9698091293295021\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5518479738751866e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5518479738751866e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8733329158020348e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8733329158020348e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9136668341153746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136668341153746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9698091293295021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9698091293295021\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5518479738751866e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5518479738751866e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8733329158020348e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8733329158020348e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9136668341153746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136668341153746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690866\tvalid_0's binary_error: 0.465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.688571\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.687584\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.698766\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.714073\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.708936\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.715591\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.718323\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.719683\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.722853\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.718691\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.71735\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.72028\tvalid_0's binary_error: 0.455\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.687584\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9698091293295021, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9698091293295021\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.5518479738751866e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.5518479738751866e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8733329158020348e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8733329158020348e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9136668341153746, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9136668341153746\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.52\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9911414324673796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9911414324673796\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007531463018402133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007531463018402133\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.488337032772606e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.488337032772606e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8940038518713825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8940038518713825\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9911414324673796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9911414324673796\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007531463018402133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007531463018402133\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.488337032772606e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.488337032772606e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8940038518713825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8940038518713825\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9911414324673796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9911414324673796\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007531463018402133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007531463018402133\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.488337032772606e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.488337032772606e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8940038518713825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8940038518713825\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.696192\tvalid_0's binary_error: 0.45\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.694834\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.697826\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.698309\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.710051\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.716082\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.724317\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.731837\tvalid_0's binary_error: 0.535\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.735174\tvalid_0's binary_error: 0.545\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.730669\tvalid_0's binary_error: 0.55\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.732355\tvalid_0's binary_error: 0.54\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.696192\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=13, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=13\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9911414324673796, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9911414324673796\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007531463018402133, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007531463018402133\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.488337032772606e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.488337032772606e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8940038518713825, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8940038518713825\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:54,500] Trial 56 finished with value: 0.44499999999999995 and parameters: {'learning_rate': 0.23442000916493458, 'num_leaves': 50, 'max_depth': 6, 'min_data_in_leaf': 12, 'feature_fraction': 0.8570213624592583, 'bagging_fraction': 0.646350602174801, 'bagging_freq': 4, 'lambda_l1': 0.004449975496271344, 'lambda_l2': 1.0970252488916538e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:54,619] Trial 57 finished with value: 0.43000000000000005 and parameters: {'learning_rate': 0.2944669365881394, 'num_leaves': 62, 'max_depth': 5, 'min_data_in_leaf': 8, 'feature_fraction': 0.8854858248347437, 'bagging_fraction': 0.9316117726013255, 'bagging_freq': 3, 'lambda_l1': 0.0008841972090017196, 'lambda_l2': 3.147508335586143e-06}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8570213624592583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8570213624592583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004449975496271344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004449975496271344\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0970252488916538e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0970252488916538e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646350602174801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.646350602174801\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8570213624592583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8570213624592583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004449975496271344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004449975496271344\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0970252488916538e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0970252488916538e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646350602174801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.646350602174801\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8570213624592583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8570213624592583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004449975496271344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004449975496271344\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0970252488916538e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0970252488916538e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646350602174801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.646350602174801\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690363\tvalid_0's binary_error: 0.445\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.691586\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691778\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.702256\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.700194\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.71426\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.709504\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.709228\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.716745\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.714261\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.712437\tvalid_0's binary_error: 0.485\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.690363\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=12, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=12\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8570213624592583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8570213624592583\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004449975496271344, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004449975496271344\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0970252488916538e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0970252488916538e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.646350602174801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.646350602174801\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8854858248347437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8854858248347437\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008841972090017196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008841972090017196\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.147508335586143e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.147508335586143e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9316117726013255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9316117726013255\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8854858248347437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8854858248347437\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008841972090017196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008841972090017196\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.147508335586143e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.147508335586143e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9316117726013255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9316117726013255\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8854858248347437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8854858248347437\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008841972090017196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008841972090017196\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.147508335586143e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.147508335586143e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9316117726013255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9316117726013255\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.683365\tvalid_0's binary_error: 0.43\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.700341\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.709418\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.70685\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.704671\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.711841\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.70893\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.711026\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.722629\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.723161\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.7202\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.683365\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8854858248347437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8854858248347437\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0008841972090017196, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008841972090017196\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.147508335586143e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.147508335586143e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9316117726013255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9316117726013255\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:54,739] Trial 58 finished with value: 0.43500000000000005 and parameters: {'learning_rate': 0.20358520362564617, 'num_leaves': 45, 'max_depth': 6, 'min_data_in_leaf': 6, 'feature_fraction': 0.9413599343841421, 'bagging_fraction': 0.8553464088952422, 'bagging_freq': 5, 'lambda_l1': 3.53707900313679e-05, 'lambda_l2': 8.138517314954417e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:54,857] Trial 59 finished with value: 0.395 and parameters: {'learning_rate': 0.13337684164742375, 'num_leaves': 66, 'max_depth': 6, 'min_data_in_leaf': 3, 'feature_fraction': 0.9175332417175025, 'bagging_fraction': 0.8962433442777394, 'bagging_freq': 3, 'lambda_l1': 0.00034152352534812925, 'lambda_l2': 3.58585254506436e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9413599343841421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9413599343841421\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.53707900313679e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.53707900313679e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.138517314954417e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.138517314954417e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8553464088952422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8553464088952422\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9413599343841421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9413599343841421\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.53707900313679e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.53707900313679e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.138517314954417e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.138517314954417e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8553464088952422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8553464088952422\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9413599343841421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9413599343841421\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.53707900313679e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.53707900313679e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.138517314954417e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.138517314954417e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8553464088952422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8553464088952422\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.682719\tvalid_0's binary_error: 0.435\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.68361\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.695872\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.699641\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.699509\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.704464\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.711106\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.717274\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.721393\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.728034\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.728386\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.682719\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9413599343841421, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9413599343841421\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.53707900313679e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.53707900313679e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.138517314954417e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.138517314954417e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8553464088952422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8553464088952422\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.565\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175332417175025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175332417175025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00034152352534812925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00034152352534812925\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.58585254506436e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.58585254506436e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962433442777394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962433442777394\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175332417175025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175332417175025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00034152352534812925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00034152352534812925\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.58585254506436e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.58585254506436e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962433442777394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962433442777394\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175332417175025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175332417175025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00034152352534812925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00034152352534812925\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.58585254506436e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.58585254506436e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962433442777394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962433442777394\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.683041\tvalid_0's binary_error: 0.395\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.683503\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.682858\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.684345\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.690956\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.695626\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.696419\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.697968\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.700475\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.703521\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.700695\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.683041\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9175332417175025, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9175332417175025\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00034152352534812925, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00034152352534812925\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.58585254506436e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.58585254506436e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8962433442777394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8962433442777394\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:54,981] Trial 60 finished with value: 0.46499999999999997 and parameters: {'learning_rate': 0.2635431860079783, 'num_leaves': 53, 'max_depth': 8, 'min_data_in_leaf': 38, 'feature_fraction': 0.9665544523196906, 'bagging_fraction': 0.7901407698442682, 'bagging_freq': 1, 'lambda_l1': 0.00016539812743232666, 'lambda_l2': 5.091212180950473e-08}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:55,105] Trial 61 finished with value: 0.395 and parameters: {'learning_rate': 0.13783562098509045, 'num_leaves': 66, 'max_depth': 6, 'min_data_in_leaf': 3, 'feature_fraction': 0.9097386456259265, 'bagging_fraction': 0.8989267627235334, 'bagging_freq': 3, 'lambda_l1': 0.0005175629925661941, 'lambda_l2': 4.2820275330597675e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9665544523196906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9665544523196906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016539812743232666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016539812743232666\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091212180950473e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.091212180950473e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901407698442682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901407698442682\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9665544523196906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9665544523196906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016539812743232666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016539812743232666\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091212180950473e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.091212180950473e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901407698442682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901407698442682\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9665544523196906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9665544523196906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016539812743232666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016539812743232666\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091212180950473e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.091212180950473e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901407698442682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901407698442682\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689655\tvalid_0's binary_error: 0.48\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.687196\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.697423\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.707206\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.709501\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.71508\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.723139\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.723955\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.730964\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.731208\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.727157\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.732229\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.687196\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=38, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=38\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9665544523196906, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9665544523196906\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00016539812743232666, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00016539812743232666\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.091212180950473e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.091212180950473e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7901407698442682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901407698442682\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9097386456259265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9097386456259265\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0005175629925661941, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005175629925661941\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2820275330597675e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2820275330597675e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8989267627235334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8989267627235334\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9097386456259265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9097386456259265\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0005175629925661941, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005175629925661941\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2820275330597675e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2820275330597675e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8989267627235334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8989267627235334\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9097386456259265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9097386456259265\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0005175629925661941, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005175629925661941\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2820275330597675e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2820275330597675e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8989267627235334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8989267627235334\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.682851\tvalid_0's binary_error: 0.395\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.682739\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.685177\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.689134\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.693224\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.712363\tvalid_0's binary_error: 0.53\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.717371\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.716086\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.717222\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.71545\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.716133\tvalid_0's binary_error: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.682851\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9097386456259265, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9097386456259265\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0005175629925661941, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005175629925661941\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.2820275330597675e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.2820275330597675e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8989267627235334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8989267627235334\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:55,232] Trial 62 finished with value: 0.43500000000000005 and parameters: {'learning_rate': 0.18287750387052734, 'num_leaves': 71, 'max_depth': 6, 'min_data_in_leaf': 2, 'feature_fraction': 0.9198837601652159, 'bagging_fraction': 0.9339823500791474, 'bagging_freq': 3, 'lambda_l1': 0.00031682186724931946, 'lambda_l2': 1.787848425755382e-08}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:55,350] Trial 63 finished with value: 0.405 and parameters: {'learning_rate': 0.11424724008551035, 'num_leaves': 67, 'max_depth': 6, 'min_data_in_leaf': 10, 'feature_fraction': 0.9520999246987922, 'bagging_fraction': 0.9520942522565454, 'bagging_freq': 4, 'lambda_l1': 0.00818721477572868, 'lambda_l2': 2.2099671456334496e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9198837601652159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9198837601652159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031682186724931946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031682186724931946\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.787848425755382e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.787848425755382e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9339823500791474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9339823500791474\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9198837601652159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9198837601652159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031682186724931946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031682186724931946\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.787848425755382e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.787848425755382e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9339823500791474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9339823500791474\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9198837601652159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9198837601652159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031682186724931946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031682186724931946\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.787848425755382e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.787848425755382e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9339823500791474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9339823500791474\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.684733\tvalid_0's binary_error: 0.425\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.681073\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.681342\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.694617\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.695736\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.68695\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.689833\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.691359\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.697463\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696912\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.705048\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.70826\tvalid_0's binary_error: 0.425\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.681073\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9198837601652159, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9198837601652159\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031682186724931946, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031682186724931946\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.787848425755382e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.787848425755382e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9339823500791474, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9339823500791474\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.565\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9520999246987922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9520999246987922\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00818721477572868, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00818721477572868\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2099671456334496e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2099671456334496e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9520942522565454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9520942522565454\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9520999246987922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9520999246987922\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00818721477572868, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00818721477572868\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2099671456334496e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2099671456334496e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9520942522565454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9520942522565454\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9520999246987922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9520999246987922\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00818721477572868, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00818721477572868\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2099671456334496e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2099671456334496e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9520942522565454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9520942522565454\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.685396\tvalid_0's binary_error: 0.405\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.685141\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.685399\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.687179\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.688902\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.6907\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.693275\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.69627\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.696574\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.699957\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.699221\tvalid_0's binary_error: 0.475\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.685396\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9520999246987922, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9520999246987922\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00818721477572868, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00818721477572868\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.2099671456334496e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2099671456334496e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9520942522565454, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9520942522565454\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:55,470] Trial 64 finished with value: 0.44999999999999996 and parameters: {'learning_rate': 0.22696480975913472, 'num_leaves': 61, 'max_depth': 5, 'min_data_in_leaf': 6, 'feature_fraction': 0.8741563088013505, 'bagging_fraction': 0.8783195642469808, 'bagging_freq': 3, 'lambda_l1': 0.0014969891642715924, 'lambda_l2': 1.1561455699018183e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:55,586] Trial 65 finished with value: 0.485 and parameters: {'learning_rate': 0.2660653158420036, 'num_leaves': 76, 'max_depth': 7, 'min_data_in_leaf': 9, 'feature_fraction': 0.8933330582530148, 'bagging_fraction': 0.9849182407418683, 'bagging_freq': 2, 'lambda_l1': 8.545994267487661e-06, 'lambda_l2': 2.028770472966333e-06}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741563088013505, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741563088013505\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0014969891642715924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014969891642715924\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1561455699018183e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1561455699018183e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8783195642469808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8783195642469808\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741563088013505, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741563088013505\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0014969891642715924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014969891642715924\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1561455699018183e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1561455699018183e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8783195642469808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8783195642469808\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741563088013505, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741563088013505\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0014969891642715924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014969891642715924\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1561455699018183e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1561455699018183e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8783195642469808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8783195642469808\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.690519\tvalid_0's binary_error: 0.46\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.690795\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.685483\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.702874\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.716475\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.722075\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.73283\tvalid_0's binary_error: 0.53\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.740752\tvalid_0's binary_error: 0.535\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.740853\tvalid_0's binary_error: 0.53\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.73562\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.730403\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.730378\tvalid_0's binary_error: 0.51\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.690795\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8741563088013505, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8741563088013505\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0014969891642715924, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0014969891642715924\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1561455699018183e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1561455699018183e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8783195642469808, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8783195642469808\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.55\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8933330582530148, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8933330582530148\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.545994267487661e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.545994267487661e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.028770472966333e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.028770472966333e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9849182407418683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9849182407418683\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8933330582530148, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8933330582530148\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.545994267487661e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.545994267487661e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.028770472966333e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.028770472966333e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9849182407418683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9849182407418683\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8933330582530148, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8933330582530148\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.545994267487661e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.545994267487661e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.028770472966333e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.028770472966333e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9849182407418683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9849182407418683\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.694615\tvalid_0's binary_error: 0.485\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.693085\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.698588\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.704514\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.710975\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.719874\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.720307\tvalid_0's binary_error: 0.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.717839\tvalid_0's binary_error: 0.52\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.720803\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.717113\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.718077\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.694615\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8933330582530148, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8933330582530148\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.545994267487661e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.545994267487661e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.028770472966333e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.028770472966333e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9849182407418683, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9849182407418683\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:55,712] Trial 66 finished with value: 0.44499999999999995 and parameters: {'learning_rate': 0.10370343238382582, 'num_leaves': 58, 'max_depth': 5, 'min_data_in_leaf': 3, 'feature_fraction': 0.932736167848642, 'bagging_fraction': 0.9182140335953239, 'bagging_freq': 4, 'lambda_l1': 0.003293025718345062, 'lambda_l2': 0.0013025755344750326}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:55,855] Trial 67 finished with value: 0.41000000000000003 and parameters: {'learning_rate': 0.16926266975955198, 'num_leaves': 32, 'max_depth': 7, 'min_data_in_leaf': 5, 'feature_fraction': 0.9827400435039795, 'bagging_fraction': 0.8938964692825642, 'bagging_freq': 5, 'lambda_l1': 0.0007585788905647169, 'lambda_l2': 9.506253608884342e-07}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.932736167848642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.932736167848642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003293025718345062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003293025718345062\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013025755344750326, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013025755344750326\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9182140335953239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9182140335953239\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.932736167848642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.932736167848642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003293025718345062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003293025718345062\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013025755344750326, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013025755344750326\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9182140335953239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9182140335953239\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.932736167848642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.932736167848642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003293025718345062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003293025718345062\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013025755344750326, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013025755344750326\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9182140335953239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9182140335953239\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.689205\tvalid_0's binary_error: 0.45\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.68651\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.684904\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.68938\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.695837\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.691796\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.696417\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.697986\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.695816\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.696855\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.6949\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.697838\tvalid_0's binary_error: 0.475\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.68651\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.932736167848642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.932736167848642\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.003293025718345062, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003293025718345062\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0013025755344750326, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013025755344750326\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9182140335953239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9182140335953239\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.555\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9827400435039795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9827400435039795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007585788905647169, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007585788905647169\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.506253608884342e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.506253608884342e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8938964692825642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8938964692825642\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9827400435039795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9827400435039795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007585788905647169, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007585788905647169\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.506253608884342e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.506253608884342e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8938964692825642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8938964692825642\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9827400435039795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9827400435039795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007585788905647169, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007585788905647169\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.506253608884342e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.506253608884342e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8938964692825642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8938964692825642\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[1]\tvalid_0's binary_logloss: 0.687157\tvalid_0's binary_error: 0.42\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.682039\tvalid_0's binary_error: 0.415\n",
      "[3]\tvalid_0's binary_logloss: 0.678198\tvalid_0's binary_error: 0.43\n",
      "[4]\tvalid_0's binary_logloss: 0.671103\tvalid_0's binary_error: 0.41\n",
      "[5]\tvalid_0's binary_logloss: 0.677271\tvalid_0's binary_error: 0.42\n",
      "[6]\tvalid_0's binary_logloss: 0.68525\tvalid_0's binary_error: 0.455\n",
      "[7]\tvalid_0's binary_logloss: 0.700473\tvalid_0's binary_error: 0.47\n",
      "[8]\tvalid_0's binary_logloss: 0.689645\tvalid_0's binary_error: 0.45\n",
      "[9]\tvalid_0's binary_logloss: 0.699245\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.704779\tvalid_0's binary_error: 0.46\n",
      "[11]\tvalid_0's binary_logloss: 0.710849\tvalid_0's binary_error: 0.48\n",
      "[12]\tvalid_0's binary_logloss: 0.711315\tvalid_0's binary_error: 0.495\n",
      "[13]\tvalid_0's binary_logloss: 0.714188\tvalid_0's binary_error: 0.5\n",
      "[14]\tvalid_0's binary_logloss: 0.712289\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.671103\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9827400435039795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9827400435039795\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007585788905647169, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007585788905647169\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.506253608884342e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.506253608884342e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8938964692825642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8938964692825642\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:55,990] Trial 68 finished with value: 0.37 and parameters: {'learning_rate': 0.1908917062719424, 'num_leaves': 73, 'max_depth': 8, 'min_data_in_leaf': 7, 'feature_fraction': 0.913642660951231, 'bagging_fraction': 0.9571937239540682, 'bagging_freq': 6, 'lambda_l1': 4.724393193801954e-05, 'lambda_l2': 1.3593497372034189e-05}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:56,100] Trial 69 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.237481413473586, 'num_leaves': 80, 'max_depth': 8, 'min_data_in_leaf': 11, 'feature_fraction': 0.8528177113221385, 'bagging_fraction': 0.9619827878335383, 'bagging_freq': 6, 'lambda_l1': 6.911310644413065e-06, 'lambda_l2': 3.3354816733533046e-06}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.913642660951231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.913642660951231\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.724393193801954e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.724393193801954e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3593497372034189e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3593497372034189e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9571937239540682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9571937239540682\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.913642660951231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.913642660951231\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.724393193801954e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.724393193801954e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3593497372034189e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3593497372034189e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9571937239540682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9571937239540682\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.913642660951231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.913642660951231\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.724393193801954e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.724393193801954e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3593497372034189e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3593497372034189e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9571937239540682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9571937239540682\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.682528\tvalid_0's binary_error: 0.42\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.675106\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.668113\tvalid_0's binary_error: 0.37\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.672348\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.684859\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.683854\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.68697\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.688392\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.702167\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.711099\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.712237\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.718117\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.725704\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.668113\tvalid_0's binary_error: 0.37\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.913642660951231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.913642660951231\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.724393193801954e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.724393193801954e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3593497372034189e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3593497372034189e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9571937239540682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9571937239540682\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Accuracy-> 0.63\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528177113221385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528177113221385\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.911310644413065e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.911310644413065e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3354816733533046e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3354816733533046e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619827878335383, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619827878335383\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528177113221385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528177113221385\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.911310644413065e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.911310644413065e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3354816733533046e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3354816733533046e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619827878335383, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619827878335383\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528177113221385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528177113221385\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.911310644413065e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.911310644413065e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3354816733533046e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3354816733533046e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619827878335383, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619827878335383\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.680478\tvalid_0's binary_error: 0.415\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.696134\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.697585\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.70739\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.706721\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.714048\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.719152\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.717884\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.718969\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.720797\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.719657\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.680478\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=11, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=11\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8528177113221385, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8528177113221385\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.911310644413065e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.911310644413065e-06\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.3354816733533046e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.3354816733533046e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9619827878335383, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9619827878335383\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Accuracy-> 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:56,231] Trial 70 finished with value: 0.45499999999999996 and parameters: {'learning_rate': 0.1882813274425744, 'num_leaves': 82, 'max_depth': 8, 'min_data_in_leaf': 7, 'feature_fraction': 0.9568657297957348, 'bagging_fraction': 0.9844478517312186, 'bagging_freq': 6, 'lambda_l1': 5.860037626073432e-05, 'lambda_l2': 8.968544025947226e-06}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:56,341] Trial 71 finished with value: 0.4 and parameters: {'learning_rate': 0.20788002489138685, 'num_leaves': 67, 'max_depth': 6, 'min_data_in_leaf': 2, 'feature_fraction': 0.914021682287776, 'bagging_fraction': 0.939491423985334, 'bagging_freq': 2, 'lambda_l1': 0.0001387067091761691, 'lambda_l2': 1.6182136804797212e-05}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9568657297957348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9568657297957348\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.860037626073432e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.860037626073432e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.968544025947226e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.968544025947226e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9844478517312186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9844478517312186\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9568657297957348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9568657297957348\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.860037626073432e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.860037626073432e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.968544025947226e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.968544025947226e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9844478517312186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9844478517312186\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9568657297957348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9568657297957348\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.860037626073432e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.860037626073432e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.968544025947226e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.968544025947226e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9844478517312186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9844478517312186\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.683172\tvalid_0's binary_error: 0.47\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.677931\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.680732\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.688784\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.68351\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.701305\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.708319\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.717653\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.732759\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.737303\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.733026\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.737669\tvalid_0's binary_error: 0.48\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.677931\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9568657297957348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9568657297957348\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.860037626073432e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.860037626073432e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.968544025947226e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.968544025947226e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9844478517312186, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9844478517312186\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "Accuracy-> 0.545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914021682287776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914021682287776\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001387067091761691, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001387067091761691\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6182136804797212e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6182136804797212e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.939491423985334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939491423985334\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914021682287776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914021682287776\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001387067091761691, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001387067091761691\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6182136804797212e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6182136804797212e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.939491423985334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939491423985334\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914021682287776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914021682287776\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001387067091761691, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001387067091761691\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6182136804797212e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6182136804797212e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.939491423985334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939491423985334\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.68116\tvalid_0's binary_error: 0.42\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.678433\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.673779\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.679737\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.689823\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687679\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.6857\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.693303\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.691607\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.68586\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.697908\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.707946\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.678433\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.914021682287776, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.914021682287776\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001387067091761691, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001387067091761691\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6182136804797212e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6182136804797212e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.939491423985334, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939491423985334\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:56,475] Trial 72 finished with value: 0.42000000000000004 and parameters: {'learning_rate': 0.27255917154628195, 'num_leaves': 73, 'max_depth': 7, 'min_data_in_leaf': 5, 'feature_fraction': 0.878301162057851, 'bagging_fraction': 0.9250136219636748, 'bagging_freq': 3, 'lambda_l1': 0.004728739952176807, 'lambda_l2': 4.1650057491336767e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:56,607] Trial 73 finished with value: 0.4 and parameters: {'learning_rate': 0.12712804258458557, 'num_leaves': 69, 'max_depth': 8, 'min_data_in_leaf': 7, 'feature_fraction': 0.8948658888337753, 'bagging_fraction': 0.9067404387639153, 'bagging_freq': 5, 'lambda_l1': 0.00031446369091044817, 'lambda_l2': 4.263287869385942e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.878301162057851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.878301162057851\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004728739952176807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004728739952176807\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1650057491336767e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.1650057491336767e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9250136219636748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9250136219636748\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.878301162057851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.878301162057851\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004728739952176807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004728739952176807\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1650057491336767e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.1650057491336767e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9250136219636748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9250136219636748\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.878301162057851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.878301162057851\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004728739952176807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004728739952176807\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1650057491336767e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.1650057491336767e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9250136219636748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9250136219636748\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.679239\tvalid_0's binary_error: 0.415\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.6688\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.667571\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.672379\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.669056\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.661893\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.665021\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.674384\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.675174\tvalid_0's binary_error: 0.395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.700755\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.697909\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.704402\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.697862\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.708743\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's binary_logloss: 0.707058\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's binary_logloss: 0.71544\tvalid_0's binary_error: 0.45\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.661893\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.878301162057851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.878301162057851\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.004728739952176807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004728739952176807\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.1650057491336767e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.1650057491336767e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9250136219636748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9250136219636748\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8948658888337753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8948658888337753\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031446369091044817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031446369091044817\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.263287869385942e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.263287869385942e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9067404387639153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067404387639153\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8948658888337753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8948658888337753\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031446369091044817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031446369091044817\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.263287869385942e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.263287869385942e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9067404387639153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067404387639153\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8948658888337753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8948658888337753\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031446369091044817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031446369091044817\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.263287869385942e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.263287869385942e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9067404387639153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067404387639153\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.688989\tvalid_0's binary_error: 0.43\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.686103\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.688162\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.684217\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.691735\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.698244\tvalid_0's binary_error: 0.495\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.705178\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.706131\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.715214\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.721995\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.723314\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.726549\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.726352\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.72648\tvalid_0's binary_error: 0.465\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.684217\tvalid_0's binary_error: 0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8948658888337753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8948658888337753\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00031446369091044817, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031446369091044817\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.263287869385942e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.263287869385942e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9067404387639153, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9067404387639153\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:56,730] Trial 74 finished with value: 0.46499999999999997 and parameters: {'learning_rate': 0.1613888412340096, 'num_leaves': 78, 'max_depth': 9, 'min_data_in_leaf': 34, 'feature_fraction': 0.9315856135736992, 'bagging_fraction': 0.9612991934231365, 'bagging_freq': 7, 'lambda_l1': 0.001631344305081849, 'lambda_l2': 7.952142620528256e-05}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:56,858] Trial 75 finished with value: 0.405 and parameters: {'learning_rate': 0.2169270046329201, 'num_leaves': 64, 'max_depth': 7, 'min_data_in_leaf': 9, 'feature_fraction': 0.981126568408703, 'bagging_fraction': 0.9423717211612515, 'bagging_freq': 4, 'lambda_l1': 4.0948424590823114e-05, 'lambda_l2': 9.581164983987569e-08}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9315856135736992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9315856135736992\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001631344305081849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001631344305081849\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.952142620528256e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.952142620528256e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612991934231365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612991934231365\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9315856135736992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9315856135736992\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001631344305081849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001631344305081849\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.952142620528256e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.952142620528256e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612991934231365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612991934231365\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9315856135736992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9315856135736992\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001631344305081849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001631344305081849\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.952142620528256e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.952142620528256e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612991934231365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612991934231365\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.69525\tvalid_0's binary_error: 0.52\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.697072\tvalid_0's binary_error: 0.5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.695138\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.694224\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.698666\tvalid_0's binary_error: 0.51\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.705244\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.704349\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.706316\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.701062\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.706009\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.705605\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.700691\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.702304\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.708217\tvalid_0's binary_error: 0.48\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.694224\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=34, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=34\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9315856135736992, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9315856135736992\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001631344305081849, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001631344305081849\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.952142620528256e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.952142620528256e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9612991934231365, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9612991934231365\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Accuracy-> 0.535\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.981126568408703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.981126568408703\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0948424590823114e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0948424590823114e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581164983987569e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.581164983987569e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423717211612515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423717211612515\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.981126568408703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.981126568408703\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0948424590823114e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0948424590823114e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581164983987569e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.581164983987569e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423717211612515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423717211612515\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.981126568408703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.981126568408703\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0948424590823114e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0948424590823114e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581164983987569e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.581164983987569e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423717211612515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423717211612515\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.685336\tvalid_0's binary_error: 0.44\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.683781\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.679665\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.682001\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.687054\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.687074\tvalid_0's binary_error: 0.43\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.690877\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.703873\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.703982\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.709645\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.707237\tvalid_0's binary_error: 0.445\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.707631\tvalid_0's binary_error: 0.455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.713116\tvalid_0's binary_error: 0.47\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.679665\tvalid_0's binary_error: 0.405\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.981126568408703, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.981126568408703\n",
      "[LightGBM] [Warning] lambda_l1 is set=4.0948424590823114e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.0948424590823114e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=9.581164983987569e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.581164983987569e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9423717211612515, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9423717211612515\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Accuracy-> 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:56,981] Trial 76 finished with value: 0.41500000000000004 and parameters: {'learning_rate': 0.24136166735065373, 'num_leaves': 13, 'max_depth': 9, 'min_data_in_leaf': 1, 'feature_fraction': 0.9117927922508541, 'bagging_fraction': 0.8613079240905916, 'bagging_freq': 1, 'lambda_l1': 0.010365667809194972, 'lambda_l2': 2.8196469240170066e-07}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:57,103] Trial 77 finished with value: 0.41000000000000003 and parameters: {'learning_rate': 0.17207239833295634, 'num_leaves': 73, 'max_depth': 8, 'min_data_in_leaf': 4, 'feature_fraction': 0.939517313951583, 'bagging_fraction': 0.88326903053228, 'bagging_freq': 2, 'lambda_l1': 9.18695830764652e-05, 'lambda_l2': 1.3273147581950566e-06}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9117927922508541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9117927922508541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010365667809194972, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010365667809194972\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8196469240170066e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8196469240170066e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8613079240905916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8613079240905916\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9117927922508541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9117927922508541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010365667809194972, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010365667809194972\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8196469240170066e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8196469240170066e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8613079240905916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8613079240905916\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9117927922508541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9117927922508541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010365667809194972, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010365667809194972\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8196469240170066e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8196469240170066e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8613079240905916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8613079240905916\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[1]\tvalid_0's binary_logloss: 0.680406\tvalid_0's binary_error: 0.415\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.67617\tvalid_0's binary_error: 0.43\n",
      "[3]\tvalid_0's binary_logloss: 0.683425\tvalid_0's binary_error: 0.43\n",
      "[4]\tvalid_0's binary_logloss: 0.683475\tvalid_0's binary_error: 0.445\n",
      "[5]\tvalid_0's binary_logloss: 0.685647\tvalid_0's binary_error: 0.46\n",
      "[6]\tvalid_0's binary_logloss: 0.685888\tvalid_0's binary_error: 0.47\n",
      "[7]\tvalid_0's binary_logloss: 0.684806\tvalid_0's binary_error: 0.44\n",
      "[8]\tvalid_0's binary_logloss: 0.692354\tvalid_0's binary_error: 0.44\n",
      "[9]\tvalid_0's binary_logloss: 0.695945\tvalid_0's binary_error: 0.46\n",
      "[10]\tvalid_0's binary_logloss: 0.700973\tvalid_0's binary_error: 0.48\n",
      "[11]\tvalid_0's binary_logloss: 0.707566\tvalid_0's binary_error: 0.49\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.680406\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9117927922508541, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9117927922508541\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010365667809194972, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010365667809194972\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.8196469240170066e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8196469240170066e-07\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8613079240905916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8613079240905916\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Accuracy-> 0.585\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.939517313951583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.939517313951583\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.18695830764652e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.18695830764652e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3273147581950566e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3273147581950566e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.88326903053228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.88326903053228\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.939517313951583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.939517313951583\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.18695830764652e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.18695830764652e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3273147581950566e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3273147581950566e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.88326903053228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.88326903053228\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.939517313951583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.939517313951583\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.18695830764652e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.18695830764652e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3273147581950566e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3273147581950566e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.88326903053228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.88326903053228\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.680524\tvalid_0's binary_error: 0.41\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.678975\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.673271\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.677284\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.677486\tvalid_0's binary_error: 0.425\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.681798\tvalid_0's binary_error: 0.415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.689614\tvalid_0's binary_error: 0.42\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.694256\tvalid_0's binary_error: 0.41\n",
      "[9]\tvalid_0's binary_logloss: 0.702283\tvalid_0's binary_error: 0.435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.709366\tvalid_0's binary_error: 0.47\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.713295\tvalid_0's binary_error: 0.475\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.680524\tvalid_0's binary_error: 0.41\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.939517313951583, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.939517313951583\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.18695830764652e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.18695830764652e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.3273147581950566e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.3273147581950566e-06\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.88326903053228, subsample=1.0 will be ignored. Current value: bagging_fraction=0.88326903053228\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Accuracy-> 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-06 16:37:57,233] Trial 78 finished with value: 0.45999999999999996 and parameters: {'learning_rate': 0.1365040482567356, 'num_leaves': 76, 'max_depth': 6, 'min_data_in_leaf': 42, 'feature_fraction': 0.8427728473167979, 'bagging_fraction': 0.9732452395841047, 'bagging_freq': 3, 'lambda_l1': 1.7201644365687585e-05, 'lambda_l2': 1.6543035238777535e-08}. Best is trial 43 with value: 0.36.\n",
      "[I 2025-04-06 16:37:57,340] Trial 79 finished with value: 0.46499999999999997 and parameters: {'learning_rate': 0.19444957188987305, 'num_leaves': 59, 'max_depth': 4, 'min_data_in_leaf': 6, 'feature_fraction': 0.9557538903307901, 'bagging_fraction': 0.8234204932761837, 'bagging_freq': 5, 'lambda_l1': 0.002720931546981427, 'lambda_l2': 0.26485223430857435}. Best is trial 43 with value: 0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8427728473167979, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8427728473167979\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7201644365687585e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7201644365687585e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6543035238777535e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6543035238777535e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9732452395841047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9732452395841047\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8427728473167979, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8427728473167979\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7201644365687585e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7201644365687585e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6543035238777535e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6543035238777535e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9732452395841047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9732452395841047\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8427728473167979, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8427728473167979\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7201644365687585e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7201644365687585e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6543035238777535e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6543035238777535e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9732452395841047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9732452395841047\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.688837\tvalid_0's binary_error: 0.465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.686133\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.691088\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.698589\tvalid_0's binary_error: 0.48\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.702039\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.70379\tvalid_0's binary_error: 0.49\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.707148\tvalid_0's binary_error: 0.525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.708565\tvalid_0's binary_error: 0.505\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.708751\tvalid_0's binary_error: 0.55\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.707408\tvalid_0's binary_error: 0.53\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.707074\tvalid_0's binary_error: 0.525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.7039\tvalid_0's binary_error: 0.505\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.686133\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=42, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=42\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8427728473167979, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8427728473167979\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.7201644365687585e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7201644365687585e-05\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.6543035238777535e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6543035238777535e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9732452395841047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9732452395841047\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "Accuracy-> 0.54\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9557538903307901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9557538903307901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002720931546981427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002720931546981427\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26485223430857435, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26485223430857435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8234204932761837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8234204932761837\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9557538903307901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9557538903307901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002720931546981427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002720931546981427\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26485223430857435, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26485223430857435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8234204932761837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8234204932761837\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9557538903307901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9557538903307901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002720931546981427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002720931546981427\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26485223430857435, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26485223430857435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8234204932761837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8234204932761837\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's binary_logloss: 0.688521\tvalid_0's binary_error: 0.465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's binary_logloss: 0.689032\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's binary_logloss: 0.689955\tvalid_0's binary_error: 0.475\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's binary_logloss: 0.687924\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's binary_logloss: 0.696855\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's binary_logloss: 0.693787\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's binary_logloss: 0.698766\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's binary_logloss: 0.702087\tvalid_0's binary_error: 0.44\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's binary_logloss: 0.70617\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's binary_logloss: 0.702774\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's binary_logloss: 0.704441\tvalid_0's binary_error: 0.485\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's binary_logloss: 0.705322\tvalid_0's binary_error: 0.45\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's binary_logloss: 0.703907\tvalid_0's binary_error: 0.46\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's binary_logloss: 0.707346\tvalid_0's binary_error: 0.46\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's binary_logloss: 0.687924\tvalid_0's binary_error: 0.465\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9557538903307901, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9557538903307901\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.002720931546981427, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002720931546981427\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.26485223430857435, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.26485223430857435\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8234204932761837, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8234204932761837\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Accuracy-> 0.535\n",
      "Best parameters: {'learning_rate': 0.23106117383955713, 'num_leaves': 62, 'max_depth': 7, 'min_data_in_leaf': 4, 'feature_fraction': 0.9408951396418745, 'bagging_fraction': 0.9022683329874014, 'bagging_freq': 2, 'lambda_l1': 0.00217889325401306, 'lambda_l2': 2.6603791433841303e-07}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=80)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best parameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2ff27-f1fd-442e-a0a3-b99f48032fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ac0c48f-4a4b-44cd-814a-d489a8b78ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6978310315953775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978310315953775\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22819479722940772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22819479722940772\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9300612761617002e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9300612761617002e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9212842862468595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9212842862468595\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6978310315953775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978310315953775\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22819479722940772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22819479722940772\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9300612761617002e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9300612761617002e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9212842862468595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9212842862468595\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] Number of positive: 420, number of negative: 380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1200\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6978310315953775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978310315953775\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22819479722940772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22819479722940772\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9300612761617002e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9300612761617002e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9212842862468595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9212842862468595\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.525000 -> initscore=0.100083\n",
      "[LightGBM] [Info] Start training from score 0.100083\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's binary_logloss: 0.679509\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6978310315953775, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6978310315953775\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.22819479722940772, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.22819479722940772\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9300612761617002e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9300612761617002e-05\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9212842862468595, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9212842862468595\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Model Accuracy: 0.6050\n"
     ]
    }
   ],
   "source": [
    "# Updated best parameters\n",
    "best_params = {\n",
    "    'learning_rate': 0.04727678176799223,\n",
    "    'num_leaves': 25,\n",
    "    'max_depth': 7,\n",
    "    'min_data_in_leaf': 15,\n",
    "    'feature_fraction': 0.6978310315953775,\n",
    "    'bagging_fraction': 0.9212842862468595,\n",
    "    'bagging_freq': 10,\n",
    "    'lambda_l1': 0.22819479722940772,\n",
    "    'lambda_l2': 1.9300612761617002e-05,\n",
    "    'objective': 'binary'  # Change to 'multiclass' if it's a multi-class problem\n",
    "}\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "model = lgb.LGBMClassifier(**best_params)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    eval_set=[(X_test, y_test)], \n",
    "    eval_metric=\"logloss\", \n",
    "    callbacks=[lgb.early_stopping(10)]\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ff14922-5d80-4657-9943-8058ae7c230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open(\"retail_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b191ee9b-aa7d-4ee1-b963-2ee0cdb203de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c47fba1-912b-4085-933e-13cfd88dd479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    # Define model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy  # Optuna will maximize this metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "521c4050-c795-4511-8c35-82ceaae84a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 00:36:00,479] A new study created in memory with name: no-name-4f9fdbed-a836-469e-a6c6-7b8371694c78\n",
      "[I 2025-02-16 00:36:00,801] Trial 0 finished with value: 0.54 and parameters: {'n_estimators': 55, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.54.\n",
      "[I 2025-02-16 00:36:01,167] Trial 1 finished with value: 0.555 and parameters: {'n_estimators': 116, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:01,596] Trial 2 finished with value: 0.53 and parameters: {'n_estimators': 120, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:02,921] Trial 3 finished with value: 0.52 and parameters: {'n_estimators': 284, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:04,148] Trial 4 finished with value: 0.54 and parameters: {'n_estimators': 283, 'max_depth': 22, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:04,450] Trial 5 finished with value: 0.525 and parameters: {'n_estimators': 78, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:05,149] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 173, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:05,417] Trial 7 finished with value: 0.505 and parameters: {'n_estimators': 53, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:05,671] Trial 8 finished with value: 0.515 and parameters: {'n_estimators': 68, 'max_depth': 12, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:06,026] Trial 9 finished with value: 0.525 and parameters: {'n_estimators': 107, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:06,823] Trial 10 finished with value: 0.515 and parameters: {'n_estimators': 201, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:07,306] Trial 11 finished with value: 0.555 and parameters: {'n_estimators': 141, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.555.\n",
      "[I 2025-02-16 00:36:07,790] Trial 12 finished with value: 0.56 and parameters: {'n_estimators': 144, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:08,689] Trial 13 finished with value: 0.515 and parameters: {'n_estimators': 203, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:09,219] Trial 14 finished with value: 0.56 and parameters: {'n_estimators': 162, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:09,897] Trial 15 finished with value: 0.515 and parameters: {'n_estimators': 163, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:10,822] Trial 16 finished with value: 0.525 and parameters: {'n_estimators': 217, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:11,843] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 237, 'max_depth': 15, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:12,310] Trial 18 finished with value: 0.56 and parameters: {'n_estimators': 146, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:13,300] Trial 19 finished with value: 0.535 and parameters: {'n_estimators': 248, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:13,779] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 98, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.56.\n",
      "[I 2025-02-16 00:36:14,271] Trial 21 finished with value: 0.575 and parameters: {'n_estimators': 147, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:14,805] Trial 22 finished with value: 0.53 and parameters: {'n_estimators': 146, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:15,378] Trial 23 finished with value: 0.57 and parameters: {'n_estimators': 186, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:16,169] Trial 24 finished with value: 0.525 and parameters: {'n_estimators': 192, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:16,811] Trial 25 finished with value: 0.56 and parameters: {'n_estimators': 185, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:17,455] Trial 26 finished with value: 0.52 and parameters: {'n_estimators': 129, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:17,822] Trial 27 finished with value: 0.525 and parameters: {'n_estimators': 90, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:18,799] Trial 28 finished with value: 0.54 and parameters: {'n_estimators': 229, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:19,911] Trial 29 finished with value: 0.51 and parameters: {'n_estimators': 258, 'max_depth': 27, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:20,519] Trial 30 finished with value: 0.53 and parameters: {'n_estimators': 163, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:21,033] Trial 31 finished with value: 0.56 and parameters: {'n_estimators': 162, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:21,483] Trial 32 finished with value: 0.56 and parameters: {'n_estimators': 131, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:22,153] Trial 33 finished with value: 0.545 and parameters: {'n_estimators': 172, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:22,748] Trial 34 finished with value: 0.545 and parameters: {'n_estimators': 151, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:23,183] Trial 35 finished with value: 0.56 and parameters: {'n_estimators': 116, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:23,938] Trial 36 finished with value: 0.515 and parameters: {'n_estimators': 188, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:24,475] Trial 37 finished with value: 0.525 and parameters: {'n_estimators': 127, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:25,201] Trial 38 finished with value: 0.56 and parameters: {'n_estimators': 212, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:26,056] Trial 39 finished with value: 0.52 and parameters: {'n_estimators': 180, 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:26,655] Trial 40 finished with value: 0.53 and parameters: {'n_estimators': 156, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:27,136] Trial 41 finished with value: 0.575 and parameters: {'n_estimators': 140, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.575.\n",
      "[I 2025-02-16 00:36:27,627] Trial 42 finished with value: 0.59 and parameters: {'n_estimators': 137, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:28,079] Trial 43 finished with value: 0.57 and parameters: {'n_estimators': 114, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:28,511] Trial 44 finished with value: 0.52 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:28,935] Trial 45 finished with value: 0.54 and parameters: {'n_estimators': 108, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:29,234] Trial 46 finished with value: 0.535 and parameters: {'n_estimators': 76, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:29,818] Trial 47 finished with value: 0.495 and parameters: {'n_estimators': 134, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:30,251] Trial 48 finished with value: 0.53 and parameters: {'n_estimators': 112, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:30,834] Trial 49 finished with value: 0.52 and parameters: {'n_estimators': 121, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:31,453] Trial 50 finished with value: 0.535 and parameters: {'n_estimators': 174, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:31,921] Trial 51 finished with value: 0.57 and parameters: {'n_estimators': 138, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:32,411] Trial 52 finished with value: 0.575 and parameters: {'n_estimators': 138, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:32,881] Trial 53 finished with value: 0.545 and parameters: {'n_estimators': 123, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:34,133] Trial 54 finished with value: 0.505 and parameters: {'n_estimators': 298, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:34,471] Trial 55 finished with value: 0.535 and parameters: {'n_estimators': 92, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:34,975] Trial 56 finished with value: 0.585 and parameters: {'n_estimators': 141, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:35,769] Trial 57 finished with value: 0.51 and parameters: {'n_estimators': 198, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:36,324] Trial 58 finished with value: 0.555 and parameters: {'n_estimators': 140, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:37,223] Trial 59 finished with value: 0.555 and parameters: {'n_estimators': 154, 'max_depth': 21, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:37,861] Trial 60 finished with value: 0.535 and parameters: {'n_estimators': 169, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:38,396] Trial 61 finished with value: 0.545 and parameters: {'n_estimators': 147, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:38,855] Trial 62 finished with value: 0.575 and parameters: {'n_estimators': 137, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:39,302] Trial 63 finished with value: 0.57 and parameters: {'n_estimators': 133, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:39,822] Trial 64 finished with value: 0.55 and parameters: {'n_estimators': 155, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:40,436] Trial 65 finished with value: 0.54 and parameters: {'n_estimators': 143, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:41,237] Trial 66 finished with value: 0.52 and parameters: {'n_estimators': 182, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:42,033] Trial 67 finished with value: 0.49 and parameters: {'n_estimators': 165, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:42,393] Trial 68 finished with value: 0.545 and parameters: {'n_estimators': 101, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:42,855] Trial 69 finished with value: 0.565 and parameters: {'n_estimators': 123, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:43,462] Trial 70 finished with value: 0.505 and parameters: {'n_estimators': 157, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:43,905] Trial 71 finished with value: 0.56 and parameters: {'n_estimators': 115, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:44,408] Trial 72 finished with value: 0.56 and parameters: {'n_estimators': 134, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:44,660] Trial 73 finished with value: 0.52 and parameters: {'n_estimators': 62, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:45,227] Trial 74 finished with value: 0.565 and parameters: {'n_estimators': 147, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:45,669] Trial 75 finished with value: 0.555 and parameters: {'n_estimators': 126, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:46,107] Trial 76 finished with value: 0.52 and parameters: {'n_estimators': 105, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:46,730] Trial 77 finished with value: 0.53 and parameters: {'n_estimators': 137, 'max_depth': 28, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:47,135] Trial 78 finished with value: 0.5 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:47,547] Trial 79 finished with value: 0.545 and parameters: {'n_estimators': 113, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:48,129] Trial 80 finished with value: 0.53 and parameters: {'n_estimators': 149, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:48,577] Trial 81 finished with value: 0.565 and parameters: {'n_estimators': 128, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:49,049] Trial 82 finished with value: 0.575 and parameters: {'n_estimators': 142, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:49,620] Trial 83 finished with value: 0.545 and parameters: {'n_estimators': 160, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:50,032] Trial 84 finished with value: 0.545 and parameters: {'n_estimators': 118, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:50,562] Trial 85 finished with value: 0.55 and parameters: {'n_estimators': 141, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:51,266] Trial 86 finished with value: 0.545 and parameters: {'n_estimators': 176, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:51,917] Trial 87 finished with value: 0.53 and parameters: {'n_estimators': 168, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:52,561] Trial 88 finished with value: 0.565 and parameters: {'n_estimators': 195, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:53,302] Trial 89 finished with value: 0.54 and parameters: {'n_estimators': 212, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:53,849] Trial 90 finished with value: 0.56 and parameters: {'n_estimators': 151, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:54,322] Trial 91 finished with value: 0.555 and parameters: {'n_estimators': 140, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:54,779] Trial 92 finished with value: 0.57 and parameters: {'n_estimators': 132, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:55,220] Trial 93 finished with value: 0.575 and parameters: {'n_estimators': 120, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:55,642] Trial 94 finished with value: 0.55 and parameters: {'n_estimators': 110, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:56,146] Trial 95 finished with value: 0.525 and parameters: {'n_estimators': 120, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:56,450] Trial 96 finished with value: 0.535 and parameters: {'n_estimators': 81, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:56,938] Trial 97 finished with value: 0.515 and parameters: {'n_estimators': 126, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:57,622] Trial 98 finished with value: 0.52 and parameters: {'n_estimators': 144, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 42 with value: 0.59.\n",
      "[I 2025-02-16 00:36:58,401] Trial 99 finished with value: 0.505 and parameters: {'n_estimators': 190, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 42 with value: 0.59.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 137, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 2}\n",
      "Best accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")  # We want to maximize accuracy\n",
    "study.optimize(objective, n_trials=100)  # Run 50 trials\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e9dac-3984-4993-a4a6-12d777d57cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
